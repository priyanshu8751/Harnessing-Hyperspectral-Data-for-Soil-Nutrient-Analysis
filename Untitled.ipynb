{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72e793a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL UTILITIES\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from  tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# MODEL DEVELOPMENT DEPENDENCIES\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d02eefbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOME CONSTANTS UTILIZED IN THE NOTEBOOK\n",
    "\n",
    "DEBUG = False\n",
    "AUGMENT_CONSTANT_RF=1\n",
    "AUGMENT_CONSTANT_KNN=6\n",
    "LABEL_NAMES = [\"P2O5\", \"K\", \"Mg\", \"pH\"]\n",
    "LABEL_MAXS = np.array([70.3026558891455, 227.9885103926097, 159.28123556581986, 6.782719399538106])\n",
    "#Y_BASE_FACT = np.array([121764.2 / 1731.0, 394876.1 / 1731.0, 275875.1 / 1731.0, 11747.67 / 1731.0]) / LABEL_MAXS\n",
    "\n",
    "COL_IX = [0, 1, 2, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fb95872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(directory: str, gt_file_path: str, is_train=True, augment_constant: int = 0):\n",
    "    \"\"\"Load each cube, reduce its dimensionality and append to array.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Directory to either train or test set\n",
    "        gt_file_path (str): File path for the ground truth labels (expected CVS file)\n",
    "        is_train (boolean): Binary flag for setting loader for Train (TRUE) or Test (FALSE)\n",
    "        augment_constant (int): number of augmentation steps to randomly crop from the larger agricultural fields\n",
    "    Returns:\n",
    "        [type]: Tuple of lists composed of raw field (data , mask) pairs,\n",
    "                and if exists: (augmented data, augmented mask) pairs, and ground truth labels\n",
    "    \"\"\"\n",
    "    \n",
    "    datalist = []\n",
    "    masklist = []\n",
    "    aug_datalist = []\n",
    "    aug_masklist = []\n",
    "    aug_labellist = []\n",
    "\n",
    "    if is_train:\n",
    "        labels = load_gt(gt_file_path)\n",
    "\n",
    "    all_files = np.array(\n",
    "        sorted(\n",
    "            glob(os.path.join(directory, \"*.npz\")),\n",
    "            key=lambda x: int(os.path.basename(x).replace(\".npz\", \"\")),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if DEBUG:\n",
    "        all_files = all_files[:100]\n",
    "        if is_train:\n",
    "            labels = labels[:100]\n",
    "\n",
    "    for idx, file_name in tqdm(enumerate(all_files),total=len(all_files), desc=\"Loading {} data ..\"\n",
    "                               .format(\"training\" if is_train else \"test\")):\n",
    "       # We load the data into memory as provided in the example notebook of the challenge\n",
    "        with np.load(file_name) as npz:\n",
    "            mask = npz[\"mask\"]\n",
    "            data = npz[\"data\"]\n",
    "            datalist.append(data)\n",
    "            masklist.append(mask)\n",
    "            \n",
    "    # for training data we make pre-augmentation by adding some randomly cropped samples\n",
    "    if is_train: \n",
    "        for i in range(augment_constant):\n",
    "            for idx, file_name in tqdm(enumerate(all_files),total=len(all_files), desc=\"Loading augmentation {} ..\".format(i+1)):\n",
    "                # print(file_name)\n",
    "                with np.load(file_name) as npz:\n",
    "                    flag = True\n",
    "                    mask = npz[\"mask\"]\n",
    "                    data = npz[\"data\"]\n",
    "                    ma = np.max(data, keepdims=True)\n",
    "                    sh = data.shape[1:]\n",
    "                    for i in range(10): \n",
    "                        # Repeating 11x11 cropping 10 times does not mean we use all croppings:\n",
    "                        # as seen in the Flag=False below at the end of the loop, \n",
    "                        # when we reach at the good crop (not coinciding to the masked area) we stop searching \n",
    "                        \n",
    "                        # Randomly cropping the fields with 11x11 size, \n",
    "                        # and adding some noise to the cropped samples \n",
    "                        edge = 11  \n",
    "                        x = np.random.randint(sh[0] + 1 - edge)\n",
    "                        y = np.random.randint(sh[1] + 1 - edge)\n",
    "                        \n",
    "                        # get crops having meaningful pixels, not zeros\n",
    "                        if np.sum(mask[0, x : (x + edge), y : (y + edge)]) > 120: \n",
    "                            aug_data = (data[:, x : (x + edge), y : (y + edge)]\n",
    "                                        + np.random.uniform(-0.01, 0.01, (150, edge, edge)) * ma)\n",
    "                            aug_mask = mask[:, x : (x + edge), y : (y + edge)] | np.random.randint(0, 1, (150, edge, edge))\n",
    "                            \n",
    "                            flag = False #break the loop when you have a meaningful crop\n",
    "                            break\n",
    "\n",
    "                    # After having  11x11 croped sample, get another crop considering \n",
    "                    # the minimum edge length: (min_edge,min_edge)\n",
    "                    if flag: \n",
    "                        max_edge = np.max(sh)\n",
    "                        min_edge = np.min(sh)  # AUGMENT BY SHAPE\n",
    "                        edge = min_edge  # np.random.randint(16, min_edge)\n",
    "                        x = np.random.randint(sh[0] + 1 - edge)\n",
    "                        y = np.random.randint(sh[1] + 1 - edge)\n",
    "                        aug_data = (data[:, x : (x + edge), y : (y + edge)]\n",
    "                                    + np.random.uniform(-0.001, 0.001, (150, edge, edge)) * ma)\n",
    "                        aug_mask = mask[:, x : (x + edge), y : (y + edge)] | np.random.randint(0, 1, (150, edge, edge))\n",
    "\n",
    "                    aug_datalist.append(aug_data)\n",
    "                    aug_masklist.append(aug_mask)\n",
    "                    aug_labellist.append(\n",
    "                        labels[idx, :]\n",
    "                        + labels[idx, :] * np.random.uniform(-0.001, 0.001, 4)\n",
    "                    )\n",
    "\n",
    "    # do pre-augmentation only for training data\n",
    "    if is_train: \n",
    "        return (datalist,\n",
    "                masklist,\n",
    "                labels,\n",
    "                aug_datalist,\n",
    "                aug_masklist,\n",
    "                np.array(aug_labellist))\n",
    "    else:\n",
    "        return datalist, masklist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16a93ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_gt(file_path: str):\n",
    "    \"\"\"Load labels for train set from the ground truth file.\n",
    "    Args:\n",
    "        file_path (str): Path to the ground truth .csv file.\n",
    "    Returns:\n",
    "        [type]: 2D numpy array with soil properties levels\n",
    "    \"\"\"\n",
    "    gt_file = pd.read_csv(file_path)\n",
    "    labels = gt_file[[\"P\", \"K\", \"Mg\", \"pH\"]].values / LABEL_MAXS  # normalize ground-truth between 0-1\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0ae4d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b16f3b45d043909f7b51b703a51dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading training data ..:   0%|          | 0/1732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982a8f984e874897acf114a683aa27e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading augmentation 1 ..:   0%|          | 0/1732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babc8c8c9ee14e18a87d2b6ee1a1be20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading augmentation 2 ..:   0%|          | 0/1732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da617c9a96cc4cb293346656fcd1b043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading augmentation 3 ..:   0%|          | 0/1732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12175864894e4140a0136bde612119f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading augmentation 4 ..:   0%|          | 0/1732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb158a0f43884a3e934ae27f5e3281a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading augmentation 5 ..:   0%|          | 0/1732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4435fb77456a41b795ee6894aaaacc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading augmentation 6 ..:   0%|          | 0/1732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30f94de19c94e0eb935f872b88b69c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading test data ..:   0%|          | 0/1154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 1732\n",
      "Train aug data size: 10392\n",
      "Test data size: 1154\n"
     ]
    }
   ],
   "source": [
    "# Please be sure that the directory and file locations are given correctly in your own system\n",
    "train_data_dir = \"train_data/train_data/train_data\"\n",
    "test_data_dir = \"test_data\"\n",
    "gt_data_path = \"train_data/train_data/train_gt.csv\"\n",
    "\n",
    "X_train, M_train, y_train, X_aug_train, M_aug_train, y_aug_train = load_data(train_data_dir, \n",
    "                                                                             gt_data_path, \n",
    "                                                                             is_train=True, \n",
    "                                                                             augment_constant=AUGMENT_CONSTANT_KNN)\n",
    "# Loading test raw data\n",
    "X_test, M_test = load_data(test_data_dir, \n",
    "                           gt_file_path=None, \n",
    "                           is_train=False)\n",
    "\n",
    "print(f\"Train data size: {len(X_train)}\")\n",
    "print(f\"Train aug data size: {len(X_aug_train)}\")\n",
    "print(f\"Test data size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1945571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_list, mask_list, is_for_KNN=False): \n",
    "    \"\"\"Extract high-level features from the raw field data.\n",
    "\n",
    "    Args:\n",
    "        data_list: Directory to either train or test set\n",
    "        mask_list: File path for the ground truth labels (expected CVS file)\n",
    "        is_for_KNN: Binary flag for determining if the features are generated for KNN (TRUE) or Random Forest (FALSE)\n",
    "    Returns:\n",
    "        [type]: Tuple of lists composed of (features , field size) pairs for each field, \n",
    "                where field size will be used performance analysis.\n",
    "    \"\"\"\n",
    "        \n",
    "    def _shape_pad(data):\n",
    "        # This sub-function makes padding to have square fields sizes.\n",
    "        # Not mandatory but eliminates the risk of calculation error in singular value decomposition,\n",
    "        # padding by warping also improves the performance slightly.\n",
    "        max_edge = np.max(image.shape[1:])\n",
    "        shape = (max_edge, max_edge)\n",
    "        padded = np.pad(data,((0, 0), (0, (shape[0] - data.shape[1])), (0, (shape[1] - data.shape[2]))),\"wrap\")\n",
    "        return padded\n",
    "    \n",
    "    filtering = SpectralCurveFiltering()\n",
    "    w1 = pywt.Wavelet(\"sym3\")\n",
    "    w2 = pywt.Wavelet(\"dmey\")\n",
    "\n",
    "    processed_data = []\n",
    "    average_edge = []\n",
    "\n",
    "    for idx, (data, mask) in enumerate(\n",
    "        tqdm(\n",
    "            zip(data_list, mask_list),\n",
    "            total=len(data_list),\n",
    "            position=0,\n",
    "            leave=True,\n",
    "            desc=\"INFO: Preprocessing data ...\",\n",
    "        )\n",
    "    ):\n",
    "        data = data / 2210   # max-max=5419 mean-max=2210\n",
    "        m = 1 - mask.astype(int)\n",
    "        image = data * m\n",
    "\n",
    "        average_edge.append((image.shape[1] + image.shape[2]) / 2)\n",
    "        image = _shape_pad(image)\n",
    "\n",
    "        s = np.linalg.svd(image, full_matrices=False, compute_uv=False)\n",
    "        s0 = s[:, 0]  \n",
    "        s1 = s[:, 1]  \n",
    "        s2 = s[:, 2] \n",
    "        s3 = s[:, 3]  \n",
    "        s4 = s[:, 4]   \n",
    "        dXds1 = s0 / (s1 + np.finfo(float).eps)\n",
    "\n",
    "\n",
    "        data = np.ma.MaskedArray(data, mask)\n",
    "        arr = filtering(data)\n",
    "\n",
    "        cA0, cD0 = pywt.dwt(arr, wavelet=w2, mode=\"constant\")\n",
    "        cAx, cDx = pywt.dwt(cA0[12:92], wavelet=w2, mode=\"constant\")\n",
    "        cAy, cDy = pywt.dwt(cAx[15:55], wavelet=w2, mode=\"constant\")\n",
    "        cAz, cDz = pywt.dwt(cAy[15:35], wavelet=w2, mode=\"constant\")\n",
    "        cAw2 = np.concatenate((cA0[12:92], cAx[15:55], cAy[15:35], cAz[15:25]), -1)\n",
    "        cDw2 = np.concatenate((cD0[12:92], cDx[15:55], cDy[15:35], cDz[15:25]), -1)\n",
    "\n",
    "        cA0, cD0 = pywt.dwt(arr, wavelet=w1, mode=\"constant\")\n",
    "        cAx, cDx = pywt.dwt(cA0[1:-1], wavelet=w1, mode=\"constant\")\n",
    "        cAy, cDy = pywt.dwt(cAx[1:-1], wavelet=w1, mode=\"constant\")\n",
    "        cAz, cDz = pywt.dwt(cAy[1:-1], wavelet=w1, mode=\"constant\")\n",
    "        cAw1 = np.concatenate((cA0, cAx, cAy, cAz), -1)\n",
    "        cDw1 = np.concatenate((cD0, cDx, cDy, cDz), -1)\n",
    "\n",
    "        dXdl = np.gradient(arr, axis=0)\n",
    "        d2Xdl2 = np.gradient(dXdl, axis=0)\n",
    "        d3Xdl3 = np.gradient(d2Xdl2, axis=0)\n",
    "\n",
    "\n",
    "        fft = np.fft.fft(arr)\n",
    "        real = np.real(fft)\n",
    "        imag = np.imag(fft)\n",
    "        ffts = np.fft.fft(s0)\n",
    "        reals = np.real(ffts)\n",
    "        imags = np.imag(ffts)\n",
    "\n",
    "        # The best Feature combination for Random Forest based regression\n",
    "        out_rf = np.concatenate(\n",
    "            [\n",
    "                arr,\n",
    "                dXdl,\n",
    "                d2Xdl2,\n",
    "                d3Xdl3,\n",
    "                dXds1,\n",
    "                s0,\n",
    "                s1,\n",
    "                s2,\n",
    "                s3,\n",
    "                s4,\n",
    "                real,\n",
    "                imag,\n",
    "                reals,\n",
    "                imags,\n",
    "                cAw1,\n",
    "                cAw2,\n",
    "            ],\n",
    "            -1,\n",
    "        )\n",
    "        \n",
    "        # The best Feature combination for KNN based regression\n",
    "        out_knn = np.concatenate(\n",
    "            [\n",
    "                arr,\n",
    "                dXdl,\n",
    "                d2Xdl2,\n",
    "                d3Xdl3,\n",
    "                s0,\n",
    "                s1,\n",
    "                s2,\n",
    "                s3,\n",
    "                s4,\n",
    "                real,\n",
    "                imag,\n",
    "\n",
    "            ],\n",
    "            -1,\n",
    "        )\n",
    "        \n",
    "      \n",
    "        if is_for_KNN:\n",
    "            processed_data.append(out_knn)\n",
    "        else:\n",
    "            processed_data.append(out_rf)\n",
    "\n",
    "    return np.array(processed_data), np.array(average_edge)\n",
    "\n",
    "\n",
    "\n",
    "class SpectralCurveFiltering: # Default class provided by the challenge organizers\n",
    "    \"\"\"\n",
    "    Create a histogram (a spectral curve) of a 3D cube, using the merge_function\n",
    "    to aggregate all pixels within one band. The return array will have\n",
    "    the shape of [CHANNELS_COUNT]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, merge_function=np.mean):\n",
    "        self.merge_function = merge_function\n",
    "\n",
    "    def __call__(self, sample: np.ndarray):\n",
    "        return self.merge_function(sample, axis=(1, 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0963b143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff9d627865d4ac9afb064a392bf523e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "INFO: Preprocessing data ...:   0%|          | 0/1732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b79ec7f89a4bd2be0327c6481a5916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "INFO: Preprocessing data ...:   0%|          | 0/1732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1d4acc0a4946c799c317e0e0ea526b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "INFO: Preprocessing data ...:   0%|          | 0/1154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fd76328bb048eea36afb716b6643e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "INFO: Preprocessing data ...:   0%|          | 0/1732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8200445dd05d4831a68401846496b251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "INFO: Preprocessing data ...:   0%|          | 0/10392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49e60d6340c4a129d42ea2b401f554f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "INFO: Preprocessing data ...:   0%|          | 0/1154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# preprocessed data for random forest traninig and testing\n",
    "X_tr_processed_RF, avg_edge_train = preprocess(X_train, M_train, is_for_KNN=False)\n",
    "X_aug_processed_RF, avg_edge_train_aug_RF = preprocess(X_aug_train[:len(X_train)*AUGMENT_CONSTANT_RF], M_aug_train[:len(X_train)*AUGMENT_CONSTANT_RF], is_for_KNN=False)\n",
    "X_te_processed_RF, avg_edge_test = preprocess(X_test, M_test, is_for_KNN=False)\n",
    "\n",
    "# preprocessed data for KNN traninig and testing\n",
    "X_tr_processed_KNN, avg_edge_train = preprocess(X_train, M_train, is_for_KNN=True)\n",
    "X_aug_processed_KNN, avg_edge_train_aug_KNN = preprocess(X_aug_train, M_aug_train,is_for_KNN=True)\n",
    "X_te_processed_KNN, avg_edge_test = preprocess(X_test, M_test, is_for_KNN=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d93f3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineRegressor:\n",
    "    \"\"\"\n",
    "    Baseline regressor, which calculates the mean value of the target from the training\n",
    "    data and returns it for each testing sample.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mean = 0\n",
    "\n",
    "    def fit(self, X_train: np.ndarray, y_train: np.ndarray):\n",
    "        self.mean = np.mean(y_train, axis=0)\n",
    "        self.classes_count = y_train.shape[1]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test: np.ndarray):\n",
    "        return np.full((len(X_test), self.classes_count), self.mean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b4649fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select set of labels \n",
    "\n",
    "y_train_col = y_train[:, COL_IX]  \n",
    "y_aug_train_col = y_aug_train[:len(y_train_col)*AUGMENT_CONSTANT_RF, COL_IX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "626ba662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-fold cross validation for training.\n",
    "\n",
    "kfold = KFold(shuffle=True, random_state=2022)\n",
    "kfold.get_n_splits(X_aug_train, y_aug_train_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d8b07d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS VALIDATION STEP: 0\n",
      "Prediction score: 0.1323981048004651\n",
      "CROSS VALIDATION STEP: 1\n",
      "Prediction score: 0.16214539273310202\n",
      "CROSS VALIDATION STEP: 2\n",
      "Prediction score: 0.144690032104309\n",
      "CROSS VALIDATION STEP: 3\n",
      "Prediction score: 0.16383924469687142\n",
      "CROSS VALIDATION STEP: 4\n",
      "Prediction score: 0.13816686408517312\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_forest_models = []\n",
    "baseline_regressors = []\n",
    "\n",
    "y_hat_bl = []\n",
    "y_hat_rf = []\n",
    "y_v_list_rf = []\n",
    "edge_v_list_rf = []\n",
    "\n",
    "for idx, (ix_train, ix_valid) in enumerate(kfold.split(np.arange(0, len(y_train)), avg_edge_train.astype(int))):\n",
    "    print(\"CROSS VALIDATION STEP: {}\".format(idx))\n",
    "    \n",
    "    # Merge original data with the augmented data on training set\n",
    "    X_t = np.concatenate((X_tr_processed_RF[ix_train], X_aug_processed_RF[ix_train]), axis=0)\n",
    "    y_t = np.concatenate((y_train_col[ix_train], y_aug_train_col[ix_train]), axis=0)\n",
    "    \n",
    "    # Filter out Validation set\n",
    "    X_v = X_tr_processed_RF[ix_valid]\n",
    "    y_v =y_train_col[ix_valid]\n",
    "    y_v_list_rf.append(y_v)\n",
    "    \n",
    "    #Field edge sizes will be used for performance analysis later\n",
    "    edge = avg_edge_train[ix_valid]\n",
    "    edge_v_list_rf.append(edge)\n",
    "\n",
    "    # baseline fiting\n",
    "    baseline = BaselineRegressor()\n",
    "    baseline.fit(X_t, y_t)\n",
    "    baseline_regressors.append(baseline)\n",
    "    \n",
    "    # baseline predictions\n",
    "    y_b = baseline.predict(X_v)\n",
    "    y_hat_bl.append(y_b)\n",
    "\n",
    "    # random forest fitting\n",
    "    model = RandomForestRegressor(n_estimators=1000, n_jobs=-1)\n",
    "    model.fit(X_t, y_t)  \n",
    "    random_forest_models.append(model)\n",
    "\n",
    "    # random forest predictions\n",
    "    y_hat = model.predict(X_v) \n",
    "    y_hat_rf.append(y_hat)\n",
    "    \n",
    "    print('Prediction score: {}'.format(model.score(X_v, y_v))) \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "92b8db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Result for parameter:  P2O5\n",
      "Baseline MSE:      1078.97\n",
      "Random Forest MSE: 1003.27 (-7.02 %)\n",
      "\n",
      "\n",
      "Result for parameter:  K\n",
      "Baseline MSE:      4633.82\n",
      "Random Forest MSE: 3690.66 (-20.35 %)\n",
      "\n",
      "\n",
      "Result for parameter:  Mg\n",
      "Baseline MSE:      1684.76\n",
      "Random Forest MSE: 1509.08 (-10.43 %)\n",
      "\n",
      "\n",
      "Result for parameter:  pH\n",
      "Baseline MSE:      0.07\n",
      "Random Forest MSE: 0.06 (-15.72 %)\n",
      "\n",
      "\n",
      "CV Evaluation score: 0.8662058866134414\n",
      "\n",
      "\n",
      "Result for parameter:  P2O5\n",
      "Baseline MSE:      894.49\n",
      "Random Forest MSE: 809.42 (-9.51 %)\n",
      "\n",
      "\n",
      "Result for parameter:  K\n",
      "Baseline MSE:      3913.84\n",
      "Random Forest MSE: 3158.05 (-19.31 %)\n",
      "\n",
      "\n",
      "Result for parameter:  Mg\n",
      "Baseline MSE:      1653.14\n",
      "Random Forest MSE: 1387.19 (-16.09 %)\n",
      "\n",
      "\n",
      "Result for parameter:  pH\n",
      "Baseline MSE:      0.06\n",
      "Random Forest MSE: 0.05 (-20.31 %)\n",
      "\n",
      "\n",
      "CV Evaluation score: 0.8369481378153926\n",
      "\n",
      "\n",
      "Result for parameter:  P2O5\n",
      "Baseline MSE:      861.49\n",
      "Random Forest MSE: 836.82 (-2.86 %)\n",
      "\n",
      "\n",
      "Result for parameter:  K\n",
      "Baseline MSE:      3673.52\n",
      "Random Forest MSE: 2988.65 (-18.64 %)\n",
      "\n",
      "\n",
      "Result for parameter:  Mg\n",
      "Baseline MSE:      1393.55\n",
      "Random Forest MSE: 1175.83 (-15.62 %)\n",
      "\n",
      "\n",
      "Result for parameter:  pH\n",
      "Baseline MSE:      0.06\n",
      "Random Forest MSE: 0.05 (-22.10 %)\n",
      "\n",
      "\n",
      "CV Evaluation score: 0.8519134503442349\n",
      "\n",
      "\n",
      "Result for parameter:  P2O5\n",
      "Baseline MSE:      780.82\n",
      "Random Forest MSE: 663.58 (-15.01 %)\n",
      "\n",
      "\n",
      "Result for parameter:  K\n",
      "Baseline MSE:      3985.97\n",
      "Random Forest MSE: 3223.06 (-19.14 %)\n",
      "\n",
      "\n",
      "Result for parameter:  Mg\n",
      "Baseline MSE:      1579.17\n",
      "Random Forest MSE: 1324.31 (-16.14 %)\n",
      "\n",
      "\n",
      "Result for parameter:  pH\n",
      "Baseline MSE:      0.07\n",
      "Random Forest MSE: 0.06 (-16.01 %)\n",
      "\n",
      "\n",
      "CV Evaluation score: 0.8342506320258625\n",
      "\n",
      "\n",
      "Result for parameter:  P2O5\n",
      "Baseline MSE:      734.85\n",
      "Random Forest MSE: 714.05 (-2.83 %)\n",
      "\n",
      "\n",
      "Result for parameter:  K\n",
      "Baseline MSE:      2962.59\n",
      "Random Forest MSE: 2347.26 (-20.77 %)\n",
      "\n",
      "\n",
      "Result for parameter:  Mg\n",
      "Baseline MSE:      1638.43\n",
      "Random Forest MSE: 1433.68 (-12.50 %)\n",
      "\n",
      "\n",
      "Result for parameter:  pH\n",
      "Baseline MSE:      0.08\n",
      "Random Forest MSE: 0.06 (-20.20 %)\n",
      "\n",
      "\n",
      "CV Evaluation score: 0.8592493534518936\n",
      "\n",
      "\n",
      "OVERALL CV EVALUATION SCORE: 0.8497134920501651\n"
     ]
    }
   ],
   "source": [
    "scores = 0\n",
    "for y_hat, y_b, y_v, y_e in zip(y_hat_rf, y_hat_bl, y_v_list_rf, edge_v_list_rf):\n",
    "    score = 0\n",
    "    for i in COL_IX:\n",
    "        print('\\n')\n",
    "        print(\"Result for parameter: \", LABEL_NAMES[i])\n",
    "        mse_rf = mean_squared_error(y_v[:, i] * LABEL_MAXS[i], y_hat[:, i] * LABEL_MAXS[i])\n",
    "        mse_bl = mean_squared_error(y_v[:, i] * LABEL_MAXS[i], y_b[:, i] * LABEL_MAXS[i])\n",
    "        score += mse_rf / mse_bl\n",
    "        print(f\"Baseline MSE:      {mse_bl:.2f}\")\n",
    "        print(f\"Random Forest MSE: {mse_rf:.2f} ({1e2*(mse_rf - mse_bl)/mse_bl:+.2f} %)\")\n",
    "    \n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"CV Evaluation score:\", score / 4)\n",
    "    \n",
    "    scores += score\n",
    "\n",
    "print('\\n')    \n",
    "print(\"OVERALL CV EVALUATION SCORE:\", scores / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5fca5a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = 0\n",
    "out_table = []\n",
    "\n",
    "\n",
    "for y_h, y_b, y_v, y_e in zip(y_hat_rf, y_hat_bl, y_v_list_rf, edge_v_list_rf):\n",
    "    mse_rf = np.square(\n",
    "        np.subtract(y_h * LABEL_MAXS, y_v * LABEL_MAXS)\n",
    "    )  \n",
    "    mse_bl = np.square(\n",
    "        np.subtract(y_v * LABEL_MAXS, y_b * LABEL_MAXS)\n",
    "    )  \n",
    "    row = np.zeros((len(y_h), 9))\n",
    "    row[:, 8] = y_e\n",
    "    row[:, 0:4] = mse_rf\n",
    "    row[:, 4:8] = mse_bl\n",
    "    out_table.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c8944edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate(out_table, 0)\n",
    "df = pd.DataFrame(\n",
    "    x,\n",
    "    columns=[\"P2O5\", \"K\", \"Mg\", \"pH\", \"P2O5_avg\", \"K_avg\", \"Mg_avg\", \"pH_avg\", \"Edge\"],\n",
    ")\n",
    "df.head(10)\n",
    "_, bin_edge = np.histogram(df.Edge.values, bins=4)\n",
    "\n",
    "# We have determined those bin edges after looking at the field size distribuiton\n",
    "bin_edge = [0, 11, 40, 50, 100, 110, 120, 130, 210]\n",
    "bin_edge_labels = [\n",
    "    \"0-11\",\n",
    "    \"11-40\",\n",
    "    \"40-50\",\n",
    "    \"50-100\",\n",
    "    \"100-110\",\n",
    "    \"110-120\",\n",
    "    \"120-130\",\n",
    "    \"130+\",\n",
    "]\n",
    "mse_per_edge = np.zeros((len(bin_edge) - 1, 6), dtype=object)\n",
    "\n",
    "for i in range(1, len(bin_edge)):\n",
    "    d_temp = df[(df.Edge <= bin_edge[i]) & (df.Edge > bin_edge[i - 1])]\n",
    "    mse_per_edge[i - 1, 0] = np.mean(d_temp.P2O5.values) / np.mean(\n",
    "        d_temp.P2O5_avg.values\n",
    "    )\n",
    "    mse_per_edge[i - 1, 1] = np.mean(d_temp.K.values) / np.mean(d_temp.K_avg.values)\n",
    "    mse_per_edge[i - 1, 2] = np.mean(d_temp.Mg.values) / np.mean(d_temp.Mg_avg.values)\n",
    "    mse_per_edge[i - 1, 3] = np.mean(d_temp.pH.values) / np.mean(d_temp.pH_avg.values)\n",
    "    mse_per_edge[i - 1, 5] = len(d_temp)\n",
    "    mse_per_edge[i - 1, 4] = bin_edge_labels[i - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "19d88fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P2O5</th>\n",
       "      <th>K</th>\n",
       "      <th>Mg</th>\n",
       "      <th>pH</th>\n",
       "      <th>Edge</th>\n",
       "      <th>Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.078232</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.995895</td>\n",
       "      <td>0.863004</td>\n",
       "      <td>0-11</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.494419</td>\n",
       "      <td>0.612584</td>\n",
       "      <td>0.596993</td>\n",
       "      <td>0.996446</td>\n",
       "      <td>11-40</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.720445</td>\n",
       "      <td>0.753585</td>\n",
       "      <td>0.416588</td>\n",
       "      <td>0.800227</td>\n",
       "      <td>40-50</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.711346</td>\n",
       "      <td>0.669037</td>\n",
       "      <td>0.64056</td>\n",
       "      <td>0.750026</td>\n",
       "      <td>50-100</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.925959</td>\n",
       "      <td>0.622572</td>\n",
       "      <td>0.411727</td>\n",
       "      <td>0.76694</td>\n",
       "      <td>100-110</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.874178</td>\n",
       "      <td>0.82317</td>\n",
       "      <td>0.601826</td>\n",
       "      <td>0.753652</td>\n",
       "      <td>110-120</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.885632</td>\n",
       "      <td>0.773368</td>\n",
       "      <td>0.647138</td>\n",
       "      <td>0.661051</td>\n",
       "      <td>120-130</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.793938</td>\n",
       "      <td>0.768047</td>\n",
       "      <td>0.854365</td>\n",
       "      <td>0.785494</td>\n",
       "      <td>130+</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P2O5         K        Mg        pH     Edge  Len\n",
       "0  1.078232  0.999591  0.995895  0.863004     0-11  650\n",
       "1  0.494419  0.612584  0.596993  0.996446    11-40   94\n",
       "2  0.720445  0.753585  0.416588  0.800227    40-50  326\n",
       "3  0.711346  0.669037   0.64056  0.750026   50-100  138\n",
       "4  0.925959  0.622572  0.411727   0.76694  100-110  113\n",
       "5  0.874178   0.82317  0.601826  0.753652  110-120  118\n",
       "6  0.885632  0.773368  0.647138  0.661051  120-130  132\n",
       "7  0.793938  0.768047  0.854365  0.785494     130+  161"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_out = pd.DataFrame(mse_per_edge, columns=[\"P2O5\", \"K\", \"Mg\", \"pH\", \"Edge\", \"Len\"])\n",
    "d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b12a7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_forests = []\n",
    "model = RandomForestRegressor(n_estimators=1000, n_jobs=-1)\n",
    "\n",
    "X_t = np.concatenate((X_tr_processed_RF, X_aug_processed_RF), axis=0)\n",
    "y_t = np.concatenate((y_train_col, y_aug_train_col), axis=0)\n",
    "    \n",
    "model.fit(X_t, y_t) \n",
    "\n",
    "random_forests.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "10a3df0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>Mg</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.862047</td>\n",
       "      <td>1.174686</td>\n",
       "      <td>1.065061</td>\n",
       "      <td>1.006391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.781672</td>\n",
       "      <td>1.196200</td>\n",
       "      <td>1.098421</td>\n",
       "      <td>0.996409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.179777</td>\n",
       "      <td>1.189717</td>\n",
       "      <td>0.972155</td>\n",
       "      <td>1.013842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.024419</td>\n",
       "      <td>1.135434</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>1.005109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.708664</td>\n",
       "      <td>1.115450</td>\n",
       "      <td>1.171527</td>\n",
       "      <td>0.996279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>0.701213</td>\n",
       "      <td>0.768250</td>\n",
       "      <td>0.874324</td>\n",
       "      <td>0.978958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0.670387</td>\n",
       "      <td>0.765899</td>\n",
       "      <td>0.864918</td>\n",
       "      <td>0.977137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>1.033048</td>\n",
       "      <td>1.054947</td>\n",
       "      <td>1.059199</td>\n",
       "      <td>0.984288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.696823</td>\n",
       "      <td>0.812630</td>\n",
       "      <td>0.877542</td>\n",
       "      <td>0.978979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.904410</td>\n",
       "      <td>0.949777</td>\n",
       "      <td>0.925922</td>\n",
       "      <td>0.978839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>722 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            P         K        Mg        pH\n",
       "0    0.862047  1.174686  1.065061  1.006391\n",
       "1    0.781672  1.196200  1.098421  0.996409\n",
       "2    1.179777  1.189717  0.972155  1.013842\n",
       "3    1.024419  1.135434  0.954976  1.005109\n",
       "4    0.708664  1.115450  1.171527  0.996279\n",
       "..        ...       ...       ...       ...\n",
       "717  0.701213  0.768250  0.874324  0.978958\n",
       "718  0.670387  0.765899  0.864918  0.977137\n",
       "719  1.033048  1.054947  1.059199  0.984288\n",
       "720  0.696823  0.812630  0.877542  0.978979\n",
       "721  0.904410  0.949777  0.925922  0.978839\n",
       "\n",
       "[722 rows x 4 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_large = []\n",
    "\n",
    "#make predictions on multiple models if there are more than 1 model and later mean the results over them\n",
    "for rf in random_forests:\n",
    "    pp = rf.predict(X_te_processed_RF[avg_edge_test>11, :]) #X_te_processed_RF[432:, :]\n",
    "    predictions_large.append(pp)\n",
    "\n",
    "predictions_large = np.asarray(predictions_large)\n",
    "predictions_large = np.mean(predictions_large, axis=0)\n",
    "\n",
    "submission_df = pd.DataFrame(data=predictions_large, columns=[\"P\", \"K\", \"Mg\", \"pH\"])\n",
    "submission_df.to_csv(\"submission_large.csv\", index_label=\"sample_index\")\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2110ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_tr_processed_normalized_small = np.array(X_tr_processed_KNN[0:650, :], copy=True) #avg_edge_train<=11\n",
    "X_aug_processed_normalized_large = np.array(X_aug_processed_KNN[650:1732, :], copy=True) #avg_edge_train>11\n",
    "X_te_processed_normalized = np.array(X_te_processed_KNN, copy=True)\n",
    "\n",
    "for i in range(1, AUGMENT_CONSTANT_KNN):\n",
    "    X_aug_processed_normalized_large = np.concatenate(\n",
    "        [X_aug_processed_normalized_large,\n",
    "         X_aug_processed_KNN[650 + (i * 1732) : i * 1732 + 1732, :]],0,)\n",
    "\n",
    "y_train_small = y_train[0:650, :]\n",
    "avg_edge_train_small= avg_edge_train[0:650]\n",
    "y_aug_train_large = y_aug_train[650:1732, :]\n",
    "\n",
    "for i in range(1, AUGMENT_CONSTANT_KNN):\n",
    "    y_aug_train_large = np.concatenate(\n",
    "        [y_aug_train_large, y_aug_train[650 + (i * 1732) : (i * 1732) + 1732, :]], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8b8462ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature normalization\n",
    "for i in range(int(X_tr_processed_normalized_small.shape[-1] / 150)):\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "    scaler.fit(X_tr_processed_normalized_small[:, 150 * i : 150 * i + 150])\n",
    "    \n",
    "    X_tr_processed_normalized_small[:, 150 * i : 150 * i + 150] = scaler.transform(\n",
    "        X_tr_processed_normalized_small[:, 150 * i : 150 * i + 150])\n",
    "    \n",
    "    X_aug_processed_normalized_large[:, 150 * i : 150 * i + 150] = scaler.transform(\n",
    "        X_aug_processed_normalized_large[:, 150 * i : 150 * i + 150])\n",
    "    \n",
    "    X_te_processed_normalized[:, 150 * i : 150 * i + 150] = scaler.transform(\n",
    "        X_te_processed_normalized[:, 150 * i : 150 * i + 150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "64ec202f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-fold cross validation for training.\n",
    "\n",
    "kfold = KFold(shuffle=True)\n",
    "kfold.get_n_splits(X_tr_processed_normalized_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "37943693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select set of labels \n",
    "\n",
    "y_train_small_col = y_train_small[:, COL_IX]  \n",
    "y_aug_train_large_col = y_aug_train_large[:, COL_IX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0ca09d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS VALIDATION STEP: \n",
      "Prediction score: -0.018772725461358608\n",
      "CROSS VALIDATION STEP: \n",
      "Prediction score: -0.00810915125058334\n",
      "CROSS VALIDATION STEP: \n",
      "Prediction score: -0.0070147300495334575\n",
      "CROSS VALIDATION STEP: \n",
      "Prediction score: -0.01835504870431026\n",
      "CROSS VALIDATION STEP: \n",
      "Prediction score: -0.026824485121966335\n",
      "\n",
      "\n",
      "Result for parameter:  P2O5\n",
      "Baseline MSE:      1401.53\n",
      "Random Forest MSE: 1428.22 (+1.90 %)\n",
      "\n",
      "\n",
      "Result for parameter:  K\n",
      "Baseline MSE:      2763.94\n",
      "Random Forest MSE: 2663.50 (-3.63 %)\n",
      "\n",
      "\n",
      "Result for parameter:  Mg\n",
      "Baseline MSE:      3211.15\n",
      "Random Forest MSE: 3181.24 (-0.93 %)\n",
      "\n",
      "\n",
      "Result for parameter:  pH\n",
      "Baseline MSE:      0.10\n",
      "Random Forest MSE: 0.09 (-14.69 %)\n",
      "\n",
      "\n",
      "CV Evaluation score: 0.9566153529788994\n",
      "\n",
      "\n",
      "Result for parameter:  P2O5\n",
      "Baseline MSE:      1084.11\n",
      "Random Forest MSE: 1088.12 (+0.37 %)\n",
      "\n",
      "\n",
      "Result for parameter:  K\n",
      "Baseline MSE:      2376.06\n",
      "Random Forest MSE: 2108.79 (-11.25 %)\n",
      "\n",
      "\n",
      "Result for parameter:  Mg\n",
      "Baseline MSE:      3163.78\n",
      "Random Forest MSE: 3155.77 (-0.25 %)\n",
      "\n",
      "\n",
      "Result for parameter:  pH\n",
      "Baseline MSE:      0.09\n",
      "Random Forest MSE: 0.06 (-35.66 %)\n",
      "\n",
      "\n",
      "CV Evaluation score: 0.8830229488585051\n",
      "\n",
      "\n",
      "Result for parameter:  P2O5\n",
      "Baseline MSE:      1093.73\n",
      "Random Forest MSE: 1095.49 (+0.16 %)\n",
      "\n",
      "\n",
      "Result for parameter:  K\n",
      "Baseline MSE:      3189.01\n",
      "Random Forest MSE: 3068.85 (-3.77 %)\n",
      "\n",
      "\n",
      "Result for parameter:  Mg\n",
      "Baseline MSE:      3466.30\n",
      "Random Forest MSE: 3364.83 (-2.93 %)\n",
      "\n",
      "\n",
      "Result for parameter:  pH\n",
      "Baseline MSE:      0.10\n",
      "Random Forest MSE: 0.06 (-37.02 %)\n",
      "\n",
      "\n",
      "CV Evaluation score: 0.8911246318896844\n",
      "\n",
      "\n",
      "Result for parameter:  P2O5\n",
      "Baseline MSE:      1491.14\n",
      "Random Forest MSE: 1509.03 (+1.20 %)\n",
      "\n",
      "\n",
      "Result for parameter:  K\n",
      "Baseline MSE:      4269.59\n",
      "Random Forest MSE: 4294.43 (+0.58 %)\n",
      "\n",
      "\n",
      "Result for parameter:  Mg\n",
      "Baseline MSE:      2278.15\n",
      "Random Forest MSE: 2299.36 (+0.93 %)\n",
      "\n",
      "\n",
      "Result for parameter:  pH\n",
      "Baseline MSE:      0.08\n",
      "Random Forest MSE: 0.06 (-27.25 %)\n",
      "\n",
      "\n",
      "CV Evaluation score: 0.9386674919189937\n",
      "\n",
      "\n",
      "Result for parameter:  P2O5\n",
      "Baseline MSE:      1202.34\n",
      "Random Forest MSE: 1211.33 (+0.75 %)\n",
      "\n",
      "\n",
      "Result for parameter:  K\n",
      "Baseline MSE:      1938.70\n",
      "Random Forest MSE: 1761.72 (-9.13 %)\n",
      "\n",
      "\n",
      "Result for parameter:  Mg\n",
      "Baseline MSE:      2217.57\n",
      "Random Forest MSE: 2209.42 (-0.37 %)\n",
      "\n",
      "\n",
      "Result for parameter:  pH\n",
      "Baseline MSE:      0.07\n",
      "Random Forest MSE: 0.05 (-30.93 %)\n",
      "\n",
      "\n",
      "CV Evaluation score: 0.9008050381751681\n",
      "\n",
      "\n",
      "OVERALL CV EVALUATION SCORE: 0.9140470927642502\n"
     ]
    }
   ],
   "source": [
    "#Train the model for small fields only\n",
    "\n",
    "\n",
    "KNN_models = []\n",
    "baseline_regressors = []\n",
    "\n",
    "y_hat_bl = []\n",
    "y_hat_knn = []\n",
    "y_v_list_knn = []\n",
    "edge_v_list_knn = []\n",
    "\n",
    "for idx, (ix_train, ix_valid) in enumerate(\n",
    "    kfold.split(np.arange(0, len(y_train_small)))\n",
    "):\n",
    "    print(\"CROSS VALIDATION STEP: \".format(str(idx)))\n",
    "\n",
    "    X_t = X_tr_processed_normalized_small[ix_train]\n",
    "    y_t = y_train_small_col[ix_train]\n",
    "\n",
    "    X_t = np.concatenate((X_tr_processed_normalized_small[ix_train], X_aug_processed_normalized_large), axis=0)\n",
    "    y_t = np.concatenate((y_train_small_col[ix_train], y_aug_train_large_col), axis=0)\n",
    "\n",
    "    X_v = X_tr_processed_normalized_small[ix_valid]\n",
    "    y_v = y_train_small_col[ix_valid]\n",
    "    y_v_list_knn.append(y_v)\n",
    "    \n",
    "    \n",
    "    edge = avg_edge_train_small[ix_valid]\n",
    "    edge_v_list_knn.append(edge)\n",
    "\n",
    "    # baseline training\n",
    "    baseline = BaselineRegressor()\n",
    "    baseline.fit(X_t, y_t)\n",
    "    baseline_regressors.append(baseline)\n",
    "    \n",
    "    # baseline predictions\n",
    "    y_b = baseline.predict(X_v)\n",
    "    y_hat_bl.append(y_b)\n",
    "    \n",
    "\n",
    "    # KNN training\n",
    "    model = MultiOutputRegressor(KNeighborsRegressor(n_neighbors=170, weights=\"distance\"))\n",
    "    model.fit(X_t, y_t)\n",
    "    KNN_models.append(model)\n",
    "\n",
    "    \n",
    "    # KNN predictions\n",
    "    y_hat = model.predict(X_v)  \n",
    "    y_hat_knn.append(y_hat)\n",
    "\n",
    "    \n",
    "    print('Prediction score: {}'.format(model.score(X_v, y_v))) \n",
    "\n",
    "    \n",
    "    \n",
    "scores = 0\n",
    "for y_hat, y_b, y_v, y_e in zip(y_hat_knn, y_hat_bl, y_v_list_knn, edge_v_list_knn):\n",
    "    score = 0\n",
    "    for i in COL_IX:\n",
    "        print('\\n')\n",
    "        print(\"Result for parameter: \", LABEL_NAMES[i])\n",
    "        mse_knn = mean_squared_error(y_v[:, i] * LABEL_MAXS[i], y_hat[:, i] * LABEL_MAXS[i])\n",
    "        mse_bl = mean_squared_error(y_v[:, i] * LABEL_MAXS[i], y_b[:, i] * LABEL_MAXS[i])\n",
    "        score += mse_knn / mse_bl\n",
    "        print(f\"Baseline MSE:      {mse_bl:.2f}\")\n",
    "        print(f\"Random Forest MSE: {mse_knn:.2f} ({1e2*(mse_knn - mse_bl)/mse_bl:+.2f} %)\")\n",
    "    \n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"CV Evaluation score:\", score / 4)\n",
    "    \n",
    "    scores += score\n",
    "\n",
    "print('\\n')    \n",
    "print(\"OVERALL CV EVALUATION SCORE:\", scores / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9fe77c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = 0\n",
    "out_table = []\n",
    "\n",
    "for y_h, y_b, y_v, y_e in zip(y_hat_knn, y_hat_bl, y_v_list_knn, edge_v_list_knn):\n",
    "    mse_knn = np.square(np.subtract(y_h * LABEL_MAXS, y_v * LABEL_MAXS))  \n",
    "    mse_bl = np.square(np.subtract(y_v * LABEL_MAXS, y_b * LABEL_MAXS))  \n",
    "    row = np.zeros((len(y_h), 9))\n",
    "    row[:, 8] = y_e\n",
    "    row[:, 0:4] = mse_knn\n",
    "    row[:, 4:8] = mse_bl\n",
    "    out_table.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a9d1ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/user/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "x = np.concatenate(out_table, 0)\n",
    "df = pd.DataFrame(\n",
    "    x,\n",
    "    columns=[\"P2O5\", \"K\", \"Mg\", \"pH\", \"P2O5_avg\", \"K_avg\", \"Mg_avg\", \"pH_avg\", \"Edge\"],\n",
    ")\n",
    "df.head(10)\n",
    "_, bin_edge = np.histogram(df.Edge.values, bins=4)\n",
    "# print(bin_edge)\n",
    "bin_edge = [0, 11, 40, 50, 100, 110, 120, 130, 210]\n",
    "bin_edge_labels = [\n",
    "    \"0-11\",\n",
    "    \"11-40\",\n",
    "    \"40-50\",\n",
    "    \"50-100\",\n",
    "    \"100-110\",\n",
    "    \"110-120\",\n",
    "    \"120-130\",\n",
    "    \"130+\",\n",
    "]\n",
    "mse_per_edge = np.zeros((len(bin_edge) - 1, 6), dtype=object)\n",
    "\n",
    "for i in range(1, len(bin_edge)):\n",
    "    d_temp = df[(df.Edge <= bin_edge[i]) & (df.Edge > bin_edge[i - 1])]\n",
    "    mse_per_edge[i - 1, 0] = np.mean(d_temp.P2O5.values) / np.mean(\n",
    "        d_temp.P2O5_avg.values\n",
    "    )\n",
    "    mse_per_edge[i - 1, 1] = np.mean(d_temp.K.values) / np.mean(d_temp.K_avg.values)\n",
    "    mse_per_edge[i - 1, 2] = np.mean(d_temp.Mg.values) / np.mean(d_temp.Mg_avg.values)\n",
    "    mse_per_edge[i - 1, 3] = np.mean(d_temp.pH.values) / np.mean(d_temp.pH_avg.values)\n",
    "    mse_per_edge[i - 1, 5] = len(d_temp)\n",
    "    mse_per_edge[i - 1, 4] = bin_edge_labels[i - 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aa33c751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P2O5</th>\n",
       "      <th>K</th>\n",
       "      <th>Mg</th>\n",
       "      <th>pH</th>\n",
       "      <th>Edge</th>\n",
       "      <th>Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.009461</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.991187</td>\n",
       "      <td>0.710125</td>\n",
       "      <td>0-11</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40-50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50-100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110-120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120-130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130+</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P2O5         K        Mg        pH     Edge  Len\n",
       "0  1.009461  0.955975  0.991187  0.710125     0-11  650\n",
       "1       NaN       NaN       NaN       NaN    11-40    0\n",
       "2       NaN       NaN       NaN       NaN    40-50    0\n",
       "3       NaN       NaN       NaN       NaN   50-100    0\n",
       "4       NaN       NaN       NaN       NaN  100-110    0\n",
       "5       NaN       NaN       NaN       NaN  110-120    0\n",
       "6       NaN       NaN       NaN       NaN  120-130    0\n",
       "7       NaN       NaN       NaN       NaN     130+    0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_out = pd.DataFrame(mse_per_edge, columns=[\"P2O5\", \"K\", \"Mg\", \"pH\", \"Edge\", \"Len\"])\n",
    "d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6cc914d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>Mg</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981137</td>\n",
       "      <td>0.952556</td>\n",
       "      <td>0.982475</td>\n",
       "      <td>1.014134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.961773</td>\n",
       "      <td>0.954075</td>\n",
       "      <td>1.000977</td>\n",
       "      <td>1.012516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.976418</td>\n",
       "      <td>0.959950</td>\n",
       "      <td>1.004348</td>\n",
       "      <td>1.012822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997731</td>\n",
       "      <td>0.964830</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>1.013525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995586</td>\n",
       "      <td>0.963184</td>\n",
       "      <td>1.039030</td>\n",
       "      <td>1.019582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>1.004675</td>\n",
       "      <td>0.962556</td>\n",
       "      <td>1.039782</td>\n",
       "      <td>1.019961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.987399</td>\n",
       "      <td>0.951645</td>\n",
       "      <td>0.992686</td>\n",
       "      <td>1.012927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0.994527</td>\n",
       "      <td>0.964946</td>\n",
       "      <td>1.003381</td>\n",
       "      <td>1.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>1.021472</td>\n",
       "      <td>0.976994</td>\n",
       "      <td>1.029358</td>\n",
       "      <td>1.019449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.985560</td>\n",
       "      <td>0.956248</td>\n",
       "      <td>0.996317</td>\n",
       "      <td>1.013063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            P         K        Mg        pH\n",
       "0    0.981137  0.952556  0.982475  1.014134\n",
       "1    0.961773  0.954075  1.000977  1.012516\n",
       "2    0.976418  0.959950  1.004348  1.012822\n",
       "3    0.997731  0.964830  1.006085  1.013525\n",
       "4    0.995586  0.963184  1.039030  1.019582\n",
       "..        ...       ...       ...       ...\n",
       "427  1.004675  0.962556  1.039782  1.019961\n",
       "428  0.987399  0.951645  0.992686  1.012927\n",
       "429  0.994527  0.964946  1.003381  1.014063\n",
       "430  1.021472  0.976994  1.029358  1.019449\n",
       "431  0.985560  0.956248  0.996317  1.013063\n",
       "\n",
       "[432 rows x 4 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate the submission for the small fields\n",
    "\n",
    "predictions_small = []\n",
    "counter = 0\n",
    "for knn in KNN_models:\n",
    "    pp = knn.predict(X_te_processed_normalized[avg_edge_test<=11, :])\n",
    "    predictions_small.append(pp)\n",
    "\n",
    "predictions_small = np.asarray(predictions_small)\n",
    "\n",
    "\n",
    "predictions_small = np.mean(predictions_small, axis=0)\n",
    "\n",
    "submission_df = pd.DataFrame(data=predictions_small, columns=[\"P\", \"K\", \"Mg\", \"pH\"])\n",
    "submission_df.to_csv(\"submission_small_fields.csv\", index_label=\"sample_index\")\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "990db36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>Mg</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981137</td>\n",
       "      <td>0.952556</td>\n",
       "      <td>0.982475</td>\n",
       "      <td>1.014134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.961773</td>\n",
       "      <td>0.954075</td>\n",
       "      <td>1.000977</td>\n",
       "      <td>1.012516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.976418</td>\n",
       "      <td>0.959950</td>\n",
       "      <td>1.004348</td>\n",
       "      <td>1.012822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997731</td>\n",
       "      <td>0.964830</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>1.013525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995586</td>\n",
       "      <td>0.963184</td>\n",
       "      <td>1.039030</td>\n",
       "      <td>1.019582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>0.701213</td>\n",
       "      <td>0.768250</td>\n",
       "      <td>0.874324</td>\n",
       "      <td>0.978958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>0.670387</td>\n",
       "      <td>0.765899</td>\n",
       "      <td>0.864918</td>\n",
       "      <td>0.977137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>1.033048</td>\n",
       "      <td>1.054947</td>\n",
       "      <td>1.059199</td>\n",
       "      <td>0.984288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>0.696823</td>\n",
       "      <td>0.812630</td>\n",
       "      <td>0.877542</td>\n",
       "      <td>0.978979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>0.904410</td>\n",
       "      <td>0.949777</td>\n",
       "      <td>0.925922</td>\n",
       "      <td>0.978839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             P         K        Mg        pH\n",
       "0     0.981137  0.952556  0.982475  1.014134\n",
       "1     0.961773  0.954075  1.000977  1.012516\n",
       "2     0.976418  0.959950  1.004348  1.012822\n",
       "3     0.997731  0.964830  1.006085  1.013525\n",
       "4     0.995586  0.963184  1.039030  1.019582\n",
       "...        ...       ...       ...       ...\n",
       "1149  0.701213  0.768250  0.874324  0.978958\n",
       "1150  0.670387  0.765899  0.864918  0.977137\n",
       "1151  1.033048  1.054947  1.059199  0.984288\n",
       "1152  0.696823  0.812630  0.877542  0.978979\n",
       "1153  0.904410  0.949777  0.925922  0.978839\n",
       "\n",
       "[1154 rows x 4 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame(data=np.concatenate([predictions_small , predictions_large],axis=0), columns=[\"P\", \"K\", \"Mg\", \"pH\"])\n",
    "submission_df.to_csv(\"submission_hybrid.csv\", index_label=\"sample_index\")\n",
    "submission_df\n",
    "\n",
    "data = submission_df\n",
    "# Create new columns for labels and values\n",
    "labels = []\n",
    "values = []\n",
    "\n",
    "# Iterate through each row of the original data and expand it\n",
    "for i, row in data.iterrows():\n",
    "    for j, col in row.iteritems():\n",
    "        labels.append(f\"{i}_{j}\")\n",
    "        values.append(col)\n",
    "\n",
    "# Create a new DataFrame with the expanded data\n",
    "new_data = pd.DataFrame({\"Label\": labels, \"Value\": values})\n",
    "\n",
    "new_data.to_csv(\"submission_hybrid.csv\", index=False)\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a38c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_1d(directory, gt_file_path):\n",
    "  x_train = []\n",
    "  y_train = []\n",
    "  x_val = []\n",
    "  y_val = []\n",
    "  x_test = []\n",
    "  y_test = []\n",
    "\n",
    "  labels = load_gt(gt_file_path)\n",
    "\n",
    "  all_files = np.array(\n",
    "      sorted(\n",
    "          glob(os.path.join(directory, \"*.npz\")),\n",
    "          key=lambda x: int(os.path.basename(x).replace(\".npz\", \"\")),\n",
    "      )\n",
    "  )\n",
    "    \n",
    "  all_files = all_files[650:]\n",
    "  labels = labels[650:]\n",
    "\n",
    "  train_size = 0.8\n",
    "  val_size = 0.9\n",
    "\n",
    "  for idx, file_name in tqdm(enumerate(all_files),total=len(all_files), desc=\"Loading {} data ..\"\n",
    "                              .format(\"training\")):\n",
    "      # We load the data into memory as provided in the example notebook of the challenge\n",
    "      with np.load(file_name) as npz:\n",
    "          mask = npz[\"mask\"]\n",
    "          data = npz[\"data\"]\n",
    "          sh = data.shape[1:]\n",
    "            \n",
    "          augmented_data = []\n",
    "          for x in range(0, sh[0]):\n",
    "            for y in range(0, sh[1]):\n",
    "              if mask[0][x][y] == False:\n",
    "#                 first_diff = np.diff(data[:, x, y])\n",
    "#                 second_diff = np.diff(data[:, x, y], n=2)\n",
    "\n",
    "#                 # Pad the arrays with zeros to make their lengths compatible with the original array\n",
    "#                 first_diff_padded = np.pad(first_diff, (1, 0), mode='constant')\n",
    "#                 second_diff_padded = np.pad(second_diff, (2, 0), mode='constant')\n",
    "\n",
    "#                 # Concatenate the original array with the differentiated arrays\n",
    "#                 new_array = np.concatenate((data[:, x, y], data[:, x, y] + first_diff_padded, data[:, x, y] + second_diff_padded))\n",
    "                augmented_data.append(data[:, x, y])\n",
    "          \n",
    "          for i in range(len(augmented_data)):\n",
    "            if (i / len(augmented_data) < train_size):\n",
    "              x_train.append(augmented_data[i])\n",
    "              y_train.append(labels[idx])\n",
    "#             elif (i / len(augmented_data) < val_size):\n",
    "#               x_val.append(augmented_data[i])\n",
    "#               y_val.append(labels[idx])\n",
    "            else:\n",
    "              x_test.append(augmented_data[i])\n",
    "              y_test.append(labels[idx])\n",
    "                \n",
    "#           print(augmented_data[0][149])\n",
    "\n",
    "  return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c994cfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1533e9de484b0c91c0c1654210b39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading training data ..:   0%|          | 0/1082 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Please be sure that the directory and file locations are given correctly in your own system\n",
    "train_data_dir = \"train_data/train_data/train_data\"\n",
    "test_data_dir = \"test_data\"\n",
    "gt_data_path = \"train_data/train_data/train_gt.csv\"\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_data_1d(train_data_dir, gt_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b193cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e7a4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Concatenate, Conv1D, Dense, Flatten,\n",
    "                                     Input, MaxPooling1D, Reshape)\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def getKerasModel(model_name):\n",
    "    \"\"\"Get keras model by name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        Name of the respective model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Sequential keras model\n",
    "        Model.\n",
    "\n",
    "    \"\"\"\n",
    "    if model_name == \"LucasCNN\":\n",
    "        return LucasCNN()\n",
    "    if model_name == \"HuEtAl\":\n",
    "        return HuEtAl()\n",
    "    if model_name == \"LiuEtAl\":\n",
    "        return LiuEtAl()\n",
    "    if model_name == \"LucasResNet\":\n",
    "        return LucasResNet()\n",
    "    if model_name == \"LucasCoordConv\":\n",
    "        return LucasCoordConv()\n",
    "    print(\"Error: Model {0} not implemented.\".format(model_name))\n",
    "    return None\n",
    "\n",
    "\n",
    "def HuEtAl():\n",
    "    \"\"\"Return 1D-CNN by Wei Hu et al 2014.\"\"\"\n",
    "    seq_length = 150\n",
    "\n",
    "    # definition by Hu et al for parameter k1 and k2\n",
    "    kernel_size = seq_length // 9\n",
    "    pool_size = int((seq_length - kernel_size + 1) / 35)\n",
    "\n",
    "    inp = Input(shape=(seq_length, 1))\n",
    "\n",
    "    # CONV1\n",
    "    x = Conv1D(filters=20, kernel_size=kernel_size, activation=\"tanh\")(inp)\n",
    "    x = MaxPooling1D(pool_size)(x)\n",
    "\n",
    "    # Flatten, FC1, Softmax\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=100, activation=\"tanh\")(x)\n",
    "    x = Dense(4, activation=\"linear\")(x)\n",
    "\n",
    "    return Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "def LiuEtAl():\n",
    "    \"\"\"Return 1D-CNN by Lanfa Liu et al 2018.\"\"\"\n",
    "    seq_length = 150\n",
    "    kernel_size = 3\n",
    "\n",
    "    inp = Input(shape=(seq_length, 1))\n",
    "\n",
    "    # CONV1\n",
    "    x = Conv1D(filters=32, kernel_size=kernel_size, activation=\"relu\")(inp)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV2\n",
    "    x = Conv1D(filters=32, kernel_size=kernel_size, activation='relu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV3\n",
    "    x = Conv1D(filters=64, kernel_size=kernel_size, activation='relu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV4\n",
    "    x = Conv1D(filters=64, kernel_size=kernel_size, activation='relu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # Flatten & Softmax\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4, activation=\"linear\")(x)\n",
    "\n",
    "    return Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "def LucasCNN():\n",
    "    \"\"\"Return LucasCNN implementation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Sequential keras model\n",
    "        Model.\n",
    "\n",
    "    \"\"\"\n",
    "    seq_length = 150\n",
    "    kernel_size = 3\n",
    "    activation = \"relu\"\n",
    "    padding = \"valid\"\n",
    "\n",
    "    inp = Input(shape=(seq_length, 1))\n",
    "\n",
    "    # CONV1\n",
    "    x = Conv1D(filters=32,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(inp)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV2\n",
    "    x = Conv1D(filters=32,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV3\n",
    "    x = Conv1D(filters=64,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV4\n",
    "    x = Conv1D(filters=64,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # Flatten, FC1, FC2, Softmax\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(120, activation=activation)(x)\n",
    "    x = Dense(160, activation=activation)(x)\n",
    "    x = Dense(4, activation=\"linear\")(x)\n",
    "\n",
    "    return Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "def LucasResNet():\n",
    "    \"\"\"Return LucasResNet implementation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Sequential keras model\n",
    "        Model.\n",
    "\n",
    "    \"\"\"\n",
    "    seq_length = 150\n",
    "    kernel_size = 3\n",
    "    activation = \"relu\"\n",
    "    padding = \"same\"\n",
    "\n",
    "    inp = Input(shape=(seq_length, 1))\n",
    "\n",
    "    # CONV1\n",
    "    x = Conv1D(filters=32,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(inp)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV2\n",
    "    x = Conv1D(filters=32,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV3\n",
    "    x = Conv1D(filters=64,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV4\n",
    "    x = Conv1D(filters=64,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # Residual block\n",
    "    inp_res = Reshape((10, 15))(inp)\n",
    "    x = Concatenate(axis=-1)([x, inp_res])\n",
    "\n",
    "    # Flatten, FC1, FC2, Softmax\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(150, activation=activation)(x)\n",
    "    x = Dense(100, activation=activation)(x)\n",
    "    x = Dense(4, activation=\"linear\")(x)\n",
    "\n",
    "    return Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "def LucasCoordConv():\n",
    "    \"\"\"Return LucasCoordConv implementation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Sequential keras model\n",
    "        Model.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    seq_length = 150\n",
    "    kernel_size = 3\n",
    "    activation = \"relu\"\n",
    "    padding = \"valid\"\n",
    "\n",
    "    inp = Input(shape=(seq_length, 1))\n",
    "\n",
    "    # CoordCONV1\n",
    "    x = Conv1D(filters=32,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(inp)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV2\n",
    "    x = Conv1D(filters=64,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV3\n",
    "    x = Conv1D(filters=64,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # CONV4\n",
    "    x = Conv1D(filters=128,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # Flatte, FC1, FC2, Softmax\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation=activation)(x)\n",
    "    x = Dense(128, activation=activation)(x)\n",
    "    x = Dense(4, activation=\"linear\")(x)\n",
    "\n",
    "    return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42201059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Instantiate the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "764e89e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10342/17963 [================>.............] - ETA: 1:13 - loss: 0.0477 - mae: 0.1615"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "model = getKerasModel(\"LucasCoordConv\")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "# Train the model\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=256, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "608ff79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_testing(directory):\n",
    "  x_test = []\n",
    "  id = []\n",
    "\n",
    "  all_files = np.array(\n",
    "      sorted(\n",
    "          glob(os.path.join(directory, \"*.npz\")),\n",
    "          key=lambda x: int(os.path.basename(x).replace(\".npz\", \"\")),\n",
    "      )\n",
    "  )\n",
    "\n",
    "  train_size = 0.8\n",
    "  val_size = 0.9\n",
    "\n",
    "  for idx, file_name in tqdm(enumerate(all_files),total=len(all_files), desc=\"Loading {} data ..\"\n",
    "                              .format(\"training\")):\n",
    "      # We load the data into memory as provided in the example notebook of the challenge\n",
    "      with np.load(file_name) as npz:\n",
    "          mask = npz[\"mask\"]\n",
    "          data = npz[\"data\"]\n",
    "          sh = data.shape[1:]\n",
    "          if(sh[0] == 11 and sh[1] == 11):\n",
    "            continue\n",
    "          augmented_data = []\n",
    "          for x in range(0, sh[0]):\n",
    "            for y in range(0, sh[1]):\n",
    "              if mask[0][x][y] == False:\n",
    "                augmented_data.append(data[:, x, y])\n",
    "                \n",
    "          augmented_data = np.array(augmented_data)\n",
    "          augmented_data = scaler.transform(augmented_data)\n",
    "          pred = model.predict(augmented_data)\n",
    "          x_test.append(np.mean(pred, axis=0))\n",
    "          id.append(idx)\n",
    "    \n",
    "  x_test = np.array(x_test)\n",
    "  return id, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14358509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19afefda25f47ac8941e32d5e88c11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading training data ..:   0%|          | 0/1154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 4ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "21/21 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "46/46 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "44/44 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "47/47 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "48/48 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "234/234 [==============================] - 1s 4ms/step\n",
      "213/213 [==============================] - 1s 4ms/step\n",
      "248/248 [==============================] - 1s 4ms/step\n",
      "249/249 [==============================] - 1s 3ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "320/320 [==============================] - 1s 4ms/step\n",
      "236/236 [==============================] - 1s 4ms/step\n",
      "262/262 [==============================] - 1s 4ms/step\n",
      "150/150 [==============================] - 1s 4ms/step\n",
      "261/261 [==============================] - 1s 4ms/step\n",
      "216/216 [==============================] - 1s 3ms/step\n",
      "209/209 [==============================] - 1s 4ms/step\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "279/279 [==============================] - 1s 4ms/step\n",
      "126/126 [==============================] - 0s 3ms/step\n",
      "265/265 [==============================] - 1s 4ms/step\n",
      "157/157 [==============================] - 1s 4ms/step\n",
      "281/281 [==============================] - 1s 4ms/step\n",
      "321/321 [==============================] - 1s 4ms/step\n",
      "237/237 [==============================] - 1s 4ms/step\n",
      "148/148 [==============================] - 1s 4ms/step\n",
      "114/114 [==============================] - 0s 3ms/step\n",
      "210/210 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 4ms/step\n",
      "229/229 [==============================] - 1s 4ms/step\n",
      "237/237 [==============================] - 1s 4ms/step\n",
      "85/85 [==============================] - 0s 4ms/step\n",
      "341/341 [==============================] - 1s 4ms/step\n",
      "170/170 [==============================] - 1s 3ms/step\n",
      "177/177 [==============================] - 1s 3ms/step\n",
      "266/266 [==============================] - 1s 4ms/step\n",
      "280/280 [==============================] - 1s 4ms/step\n",
      "271/271 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "318/318 [==============================] - 1s 4ms/step\n",
      "118/118 [==============================] - 0s 3ms/step\n",
      "93/93 [==============================] - 0s 3ms/step\n",
      "304/304 [==============================] - 1s 3ms/step\n",
      "144/144 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "239/239 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "205/205 [==============================] - 1s 4ms/step\n",
      "114/114 [==============================] - 0s 3ms/step\n",
      "89/89 [==============================] - 0s 3ms/step\n",
      "115/115 [==============================] - 0s 4ms/step\n",
      "189/189 [==============================] - 1s 4ms/step\n",
      "137/137 [==============================] - 0s 4ms/step\n",
      "319/319 [==============================] - 1s 4ms/step\n",
      "257/257 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "365/365 [==============================] - 1s 4ms/step\n",
      "306/306 [==============================] - 1s 4ms/step\n",
      "292/292 [==============================] - 1s 4ms/step\n",
      "311/311 [==============================] - 1s 4ms/step\n",
      "192/192 [==============================] - 1s 4ms/step\n",
      "292/292 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "104/104 [==============================] - 0s 3ms/step\n",
      "335/335 [==============================] - 1s 4ms/step\n",
      "236/236 [==============================] - 1s 4ms/step\n",
      "388/388 [==============================] - 1s 4ms/step\n",
      "296/296 [==============================] - 1s 4ms/step\n",
      "308/308 [==============================] - 1s 4ms/step\n",
      "275/275 [==============================] - 1s 4ms/step\n",
      "353/353 [==============================] - 1s 4ms/step\n",
      "302/302 [==============================] - 1s 4ms/step\n",
      "217/217 [==============================] - 1s 4ms/step\n",
      "401/401 [==============================] - 2s 4ms/step\n",
      "170/170 [==============================] - 1s 3ms/step\n",
      "206/206 [==============================] - 1s 4ms/step\n",
      "442/442 [==============================] - 2s 4ms/step\n",
      "191/191 [==============================] - 1s 3ms/step\n",
      "184/184 [==============================] - 1s 3ms/step\n",
      "151/151 [==============================] - 1s 4ms/step\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "294/294 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "326/326 [==============================] - 1s 3ms/step\n",
      "284/284 [==============================] - 1s 4ms/step\n",
      "214/214 [==============================] - 1s 3ms/step\n",
      "145/145 [==============================] - 0s 3ms/step\n",
      "317/317 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "248/248 [==============================] - 1s 3ms/step\n",
      "279/279 [==============================] - 1s 4ms/step\n",
      "155/155 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "260/260 [==============================] - 1s 4ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "330/330 [==============================] - 1s 4ms/step\n",
      "287/287 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "213/213 [==============================] - 1s 4ms/step\n",
      "89/89 [==============================] - 0s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "212/212 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "281/281 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "168/168 [==============================] - 1s 3ms/step\n",
      "327/327 [==============================] - 1s 4ms/step\n",
      "320/320 [==============================] - 1s 4ms/step\n",
      "292/292 [==============================] - 1s 4ms/step\n",
      "216/216 [==============================] - 1s 4ms/step\n",
      "117/117 [==============================] - 0s 3ms/step\n",
      "322/322 [==============================] - 1s 4ms/step\n",
      "247/247 [==============================] - 1s 4ms/step\n",
      "288/288 [==============================] - 1s 4ms/step\n",
      "328/328 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "326/326 [==============================] - 1s 4ms/step\n",
      "186/186 [==============================] - 1s 4ms/step\n",
      "342/342 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "281/281 [==============================] - 1s 4ms/step\n",
      "256/256 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "186/186 [==============================] - 1s 3ms/step\n",
      "183/183 [==============================] - 1s 3ms/step\n",
      "191/191 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "91/91 [==============================] - 0s 3ms/step\n",
      "202/202 [==============================] - 1s 4ms/step\n",
      "104/104 [==============================] - 0s 3ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "310/310 [==============================] - 1s 4ms/step\n",
      "171/171 [==============================] - 1s 4ms/step\n",
      "187/187 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "310/310 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "356/356 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "275/275 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "312/312 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "262/262 [==============================] - 1s 4ms/step\n",
      "309/309 [==============================] - 1s 4ms/step\n",
      "159/159 [==============================] - 1s 3ms/step\n",
      "206/206 [==============================] - 1s 4ms/step\n",
      "269/269 [==============================] - 1s 4ms/step\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "295/295 [==============================] - 1s 4ms/step\n",
      "338/338 [==============================] - 1s 4ms/step\n",
      "84/84 [==============================] - 0s 3ms/step\n",
      "173/173 [==============================] - 1s 4ms/step\n",
      "117/117 [==============================] - 0s 4ms/step\n",
      "197/197 [==============================] - 1s 4ms/step\n",
      "176/176 [==============================] - 1s 4ms/step\n",
      "104/104 [==============================] - 0s 3ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "194/194 [==============================] - 1s 3ms/step\n",
      "126/126 [==============================] - 0s 3ms/step\n",
      "170/170 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "358/358 [==============================] - 1s 4ms/step\n",
      "251/251 [==============================] - 1s 4ms/step\n",
      "312/312 [==============================] - 1s 4ms/step\n",
      "328/328 [==============================] - 1s 4ms/step\n",
      "327/327 [==============================] - 1s 4ms/step\n",
      "280/280 [==============================] - 1s 3ms/step\n",
      "225/225 [==============================] - 1s 4ms/step\n",
      "205/205 [==============================] - 1s 4ms/step\n",
      "304/304 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "307/307 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "200/200 [==============================] - 1s 4ms/step\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "308/308 [==============================] - 1s 4ms/step\n",
      "312/312 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "338/338 [==============================] - 1s 4ms/step\n",
      "276/276 [==============================] - 1s 4ms/step\n",
      "292/292 [==============================] - 1s 4ms/step\n",
      "267/267 [==============================] - 1s 4ms/step\n",
      "84/84 [==============================] - 0s 3ms/step\n",
      "257/257 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "144/144 [==============================] - 1s 4ms/step\n",
      "193/193 [==============================] - 1s 4ms/step\n",
      "213/213 [==============================] - 1s 4ms/step\n",
      "231/231 [==============================] - 1s 4ms/step\n",
      "178/178 [==============================] - 1s 3ms/step\n",
      "166/166 [==============================] - 1s 4ms/step\n",
      "322/322 [==============================] - 1s 4ms/step\n",
      "163/163 [==============================] - 1s 3ms/step\n",
      "166/166 [==============================] - 1s 3ms/step\n",
      "206/206 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "299/299 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "192/192 [==============================] - 1s 3ms/step\n",
      "228/228 [==============================] - 1s 3ms/step\n",
      "265/265 [==============================] - 1s 4ms/step\n",
      "252/252 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "311/311 [==============================] - 1s 4ms/step\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "81/81 [==============================] - 0s 3ms/step\n",
      "315/315 [==============================] - 1s 4ms/step\n",
      "316/316 [==============================] - 1s 4ms/step\n",
      "248/248 [==============================] - 1s 4ms/step\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "194/194 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "230/230 [==============================] - 1s 4ms/step\n",
      "141/141 [==============================] - 0s 3ms/step\n",
      "376/376 [==============================] - 1s 4ms/step\n",
      "293/293 [==============================] - 1s 4ms/step\n",
      "289/289 [==============================] - 1s 4ms/step\n",
      "262/262 [==============================] - 1s 4ms/step\n",
      "261/261 [==============================] - 1s 4ms/step\n",
      "272/272 [==============================] - 1s 4ms/step\n",
      "243/243 [==============================] - 1s 4ms/step\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "257/257 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "214/214 [==============================] - 1s 4ms/step\n",
      "293/293 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "324/324 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "201/201 [==============================] - 1s 3ms/step\n",
      "341/341 [==============================] - 1s 4ms/step\n",
      "232/232 [==============================] - 1s 3ms/step\n",
      "249/249 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "145/145 [==============================] - 1s 4ms/step\n",
      "97/97 [==============================] - 0s 4ms/step\n",
      "171/171 [==============================] - 1s 3ms/step\n",
      "238/238 [==============================] - 1s 4ms/step\n",
      "228/228 [==============================] - 1s 4ms/step\n",
      "230/230 [==============================] - 1s 4ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "235/235 [==============================] - 1s 4ms/step\n",
      "235/235 [==============================] - 1s 4ms/step\n",
      "234/234 [==============================] - 1s 4ms/step\n",
      "234/234 [==============================] - 1s 4ms/step\n",
      "234/234 [==============================] - 1s 3ms/step\n",
      "234/234 [==============================] - 1s 3ms/step\n",
      "234/234 [==============================] - 1s 4ms/step\n",
      "235/235 [==============================] - 1s 3ms/step\n",
      "225/225 [==============================] - 1s 4ms/step\n",
      "234/234 [==============================] - 1s 4ms/step\n",
      "234/234 [==============================] - 1s 4ms/step\n",
      "234/234 [==============================] - 1s 4ms/step\n",
      "198/198 [==============================] - 1s 3ms/step\n",
      "234/234 [==============================] - 1s 4ms/step\n",
      "234/234 [==============================] - 1s 4ms/step\n",
      "234/234 [==============================] - 1s 4ms/step\n",
      "199/199 [==============================] - 1s 4ms/step\n",
      "234/234 [==============================] - 1s 4ms/step\n",
      "274/274 [==============================] - 1s 4ms/step\n",
      "151/151 [==============================] - 1s 3ms/step\n",
      "233/233 [==============================] - 1s 4ms/step\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "166/166 [==============================] - 1s 4ms/step\n",
      "169/169 [==============================] - 1s 4ms/step\n",
      "200/200 [==============================] - 1s 4ms/step\n",
      "185/185 [==============================] - 1s 4ms/step\n",
      "254/254 [==============================] - 1s 4ms/step\n",
      "201/201 [==============================] - 1s 3ms/step\n",
      "221/221 [==============================] - 1s 4ms/step\n",
      "161/161 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "227/227 [==============================] - 1s 4ms/step\n",
      "312/312 [==============================] - 1s 4ms/step\n",
      "164/164 [==============================] - 1s 4ms/step\n",
      "307/307 [==============================] - 1s 4ms/step\n",
      "134/134 [==============================] - 1s 4ms/step\n",
      "233/233 [==============================] - 1s 3ms/step\n",
      "349/349 [==============================] - 1s 4ms/step\n",
      "229/229 [==============================] - 1s 3ms/step\n",
      "253/253 [==============================] - 1s 4ms/step\n",
      "277/277 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "246/246 [==============================] - 1s 4ms/step\n",
      "204/204 [==============================] - 1s 4ms/step\n",
      "159/159 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 1s 3ms/step\n",
      "247/247 [==============================] - 1s 4ms/step\n",
      "230/230 [==============================] - 1s 4ms/step\n",
      "283/283 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "288/288 [==============================] - 1s 4ms/step\n",
      "292/292 [==============================] - 1s 4ms/step\n",
      "315/315 [==============================] - 1s 4ms/step\n",
      "190/190 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "179/179 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "252/252 [==============================] - 1s 4ms/step\n",
      "260/260 [==============================] - 1s 4ms/step\n",
      "231/231 [==============================] - 1s 3ms/step\n",
      "273/273 [==============================] - 1s 4ms/step\n",
      "255/255 [==============================] - 1s 4ms/step\n",
      "294/294 [==============================] - 1s 3ms/step\n",
      "200/200 [==============================] - 1s 4ms/step\n",
      "230/230 [==============================] - 1s 3ms/step\n",
      "295/295 [==============================] - 1s 4ms/step\n",
      "350/350 [==============================] - 1s 4ms/step\n",
      "264/264 [==============================] - 1s 3ms/step\n",
      "160/160 [==============================] - 1s 3ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "288/288 [==============================] - 1s 3ms/step\n",
      "209/209 [==============================] - 1s 3ms/step\n",
      "282/282 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "247/247 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "254/254 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "164/164 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "118/118 [==============================] - 0s 3ms/step\n",
      "183/183 [==============================] - 1s 3ms/step\n",
      "320/320 [==============================] - 1s 4ms/step\n",
      "185/185 [==============================] - 1s 4ms/step\n",
      "207/207 [==============================] - 1s 4ms/step\n",
      "286/286 [==============================] - 1s 4ms/step\n",
      "299/299 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "175/175 [==============================] - 1s 3ms/step\n",
      "217/217 [==============================] - 1s 4ms/step\n",
      "263/263 [==============================] - 1s 4ms/step\n",
      "235/235 [==============================] - 1s 4ms/step\n",
      "232/232 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "231/231 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "199/199 [==============================] - 1s 4ms/step\n",
      "184/184 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "326/326 [==============================] - 1s 4ms/step\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "153/153 [==============================] - 1s 3ms/step\n",
      "151/151 [==============================] - 1s 4ms/step\n",
      "320/320 [==============================] - 1s 4ms/step\n",
      "338/338 [==============================] - 1s 4ms/step\n",
      "359/359 [==============================] - 1s 4ms/step\n",
      "140/140 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "300/300 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "177/177 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "263/263 [==============================] - 1s 4ms/step\n",
      "307/307 [==============================] - 1s 4ms/step\n",
      "301/301 [==============================] - 1s 4ms/step\n",
      "175/175 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "324/324 [==============================] - 1s 4ms/step\n",
      "362/362 [==============================] - 1s 4ms/step\n",
      "247/247 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "202/202 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "267/267 [==============================] - 1s 4ms/step\n",
      "206/206 [==============================] - 1s 4ms/step\n",
      "281/281 [==============================] - 1s 4ms/step\n",
      "312/312 [==============================] - 1s 4ms/step\n",
      "284/284 [==============================] - 1s 3ms/step\n",
      "338/338 [==============================] - 1s 4ms/step\n",
      "345/345 [==============================] - 1s 4ms/step\n",
      "303/303 [==============================] - 1s 3ms/step\n",
      "195/195 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "255/255 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "335/335 [==============================] - 1s 4ms/step\n",
      "174/174 [==============================] - 1s 4ms/step\n",
      "175/175 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "349/349 [==============================] - 1s 4ms/step\n",
      "363/363 [==============================] - 1s 4ms/step\n",
      "320/320 [==============================] - 1s 4ms/step\n",
      "200/200 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "379/379 [==============================] - 1s 4ms/step\n",
      "330/330 [==============================] - 1s 4ms/step\n",
      "203/203 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "ID, X_TEST = load_data_testing(test_data_dir)\n",
    "X_TEST = np.array(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9275f4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>Mg</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.832321</td>\n",
       "      <td>1.066686</td>\n",
       "      <td>1.016398</td>\n",
       "      <td>0.990356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.928417</td>\n",
       "      <td>1.031549</td>\n",
       "      <td>0.996127</td>\n",
       "      <td>0.991398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.015653</td>\n",
       "      <td>1.043364</td>\n",
       "      <td>1.012788</td>\n",
       "      <td>0.991213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.983772</td>\n",
       "      <td>0.981870</td>\n",
       "      <td>0.947252</td>\n",
       "      <td>0.989172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.838285</td>\n",
       "      <td>0.978639</td>\n",
       "      <td>1.040415</td>\n",
       "      <td>0.994637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>0.701544</td>\n",
       "      <td>0.738986</td>\n",
       "      <td>0.859484</td>\n",
       "      <td>0.971449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0.696051</td>\n",
       "      <td>0.758925</td>\n",
       "      <td>0.859755</td>\n",
       "      <td>0.973679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0.758008</td>\n",
       "      <td>0.822675</td>\n",
       "      <td>0.917373</td>\n",
       "      <td>0.979554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.753222</td>\n",
       "      <td>0.805982</td>\n",
       "      <td>0.864973</td>\n",
       "      <td>0.972102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.850299</td>\n",
       "      <td>0.891365</td>\n",
       "      <td>0.907568</td>\n",
       "      <td>0.981134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>722 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            P         K        Mg        pH\n",
       "0    0.832321  1.066686  1.016398  0.990356\n",
       "1    0.928417  1.031549  0.996127  0.991398\n",
       "2    1.015653  1.043364  1.012788  0.991213\n",
       "3    0.983772  0.981870  0.947252  0.989172\n",
       "4    0.838285  0.978639  1.040415  0.994637\n",
       "..        ...       ...       ...       ...\n",
       "717  0.701544  0.738986  0.859484  0.971449\n",
       "718  0.696051  0.758925  0.859755  0.973679\n",
       "719  0.758008  0.822675  0.917373  0.979554\n",
       "720  0.753222  0.805982  0.864973  0.972102\n",
       "721  0.850299  0.891365  0.907568  0.981134\n",
       "\n",
       "[722 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame(data=X_TEST, columns=[\"P\", \"K\", \"Mg\", \"pH\"])\n",
    "submission_df.to_csv(\"submission_small_fields_1d.csv\", index_label=\"sample_index\")\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3f035d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " 1000,\n",
       " 1001,\n",
       " 1002,\n",
       " 1003,\n",
       " 1004,\n",
       " 1005,\n",
       " 1006,\n",
       " 1007,\n",
       " 1008,\n",
       " 1009,\n",
       " 1010,\n",
       " 1011,\n",
       " 1012,\n",
       " 1013,\n",
       " 1014,\n",
       " 1015,\n",
       " 1016,\n",
       " 1017,\n",
       " 1018,\n",
       " 1019,\n",
       " 1020,\n",
       " 1021,\n",
       " 1022,\n",
       " 1023,\n",
       " 1024,\n",
       " 1025,\n",
       " 1026,\n",
       " 1027,\n",
       " 1028,\n",
       " 1029,\n",
       " 1030,\n",
       " 1031,\n",
       " 1032,\n",
       " 1033,\n",
       " 1034,\n",
       " 1035,\n",
       " 1036,\n",
       " 1037,\n",
       " 1038,\n",
       " 1039,\n",
       " 1040,\n",
       " 1041,\n",
       " 1042,\n",
       " 1043,\n",
       " 1044,\n",
       " 1045,\n",
       " 1046,\n",
       " 1047,\n",
       " 1048,\n",
       " 1049,\n",
       " 1050,\n",
       " 1051,\n",
       " 1052,\n",
       " 1053,\n",
       " 1054,\n",
       " 1055,\n",
       " 1056,\n",
       " 1057,\n",
       " 1058,\n",
       " 1059,\n",
       " 1060,\n",
       " 1061,\n",
       " 1062,\n",
       " 1063,\n",
       " 1064,\n",
       " 1065,\n",
       " 1066,\n",
       " 1067,\n",
       " 1068,\n",
       " 1069,\n",
       " 1070,\n",
       " 1071,\n",
       " 1072,\n",
       " 1073,\n",
       " 1074,\n",
       " 1075,\n",
       " 1076,\n",
       " 1077,\n",
       " 1078,\n",
       " 1079,\n",
       " 1080,\n",
       " 1081,\n",
       " 1082,\n",
       " 1083,\n",
       " 1084,\n",
       " 1085,\n",
       " 1086,\n",
       " 1087,\n",
       " 1088,\n",
       " 1089,\n",
       " 1090,\n",
       " 1091,\n",
       " 1092,\n",
       " 1093,\n",
       " 1094,\n",
       " 1095,\n",
       " 1096,\n",
       " 1097,\n",
       " 1098,\n",
       " 1099,\n",
       " 1100,\n",
       " 1101,\n",
       " 1102,\n",
       " 1103,\n",
       " 1104,\n",
       " 1105,\n",
       " 1106,\n",
       " 1107,\n",
       " 1108,\n",
       " 1109,\n",
       " 1110,\n",
       " 1111,\n",
       " 1112,\n",
       " 1113,\n",
       " 1114,\n",
       " 1115,\n",
       " 1116,\n",
       " 1117,\n",
       " 1118,\n",
       " 1119,\n",
       " 1120,\n",
       " 1121,\n",
       " 1122,\n",
       " 1123,\n",
       " 1124,\n",
       " 1125,\n",
       " 1126,\n",
       " 1127,\n",
       " 1128,\n",
       " 1129,\n",
       " 1130,\n",
       " 1131,\n",
       " 1132,\n",
       " 1133,\n",
       " 1134,\n",
       " 1135,\n",
       " 1136,\n",
       " 1137,\n",
       " 1138,\n",
       " 1139,\n",
       " 1140,\n",
       " 1141,\n",
       " 1142,\n",
       " 1143,\n",
       " 1144,\n",
       " 1145,\n",
       " 1146,\n",
       " 1147,\n",
       " 1148,\n",
       " 1149,\n",
       " 1150,\n",
       " 1151,\n",
       " 1152,\n",
       " 1153]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb7aad50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>Mg</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981137</td>\n",
       "      <td>0.952556</td>\n",
       "      <td>0.982475</td>\n",
       "      <td>1.014134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.961773</td>\n",
       "      <td>0.954075</td>\n",
       "      <td>1.000977</td>\n",
       "      <td>1.012516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.976418</td>\n",
       "      <td>0.959950</td>\n",
       "      <td>1.004348</td>\n",
       "      <td>1.012822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997731</td>\n",
       "      <td>0.964830</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>1.013525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995586</td>\n",
       "      <td>0.963184</td>\n",
       "      <td>1.039030</td>\n",
       "      <td>1.019582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>0.701544</td>\n",
       "      <td>0.738986</td>\n",
       "      <td>0.859484</td>\n",
       "      <td>0.971449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>0.696051</td>\n",
       "      <td>0.758925</td>\n",
       "      <td>0.859755</td>\n",
       "      <td>0.973679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>0.758008</td>\n",
       "      <td>0.822675</td>\n",
       "      <td>0.917373</td>\n",
       "      <td>0.979554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>0.753222</td>\n",
       "      <td>0.805982</td>\n",
       "      <td>0.864973</td>\n",
       "      <td>0.972102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>0.850299</td>\n",
       "      <td>0.891365</td>\n",
       "      <td>0.907568</td>\n",
       "      <td>0.981134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             P         K        Mg        pH\n",
       "0     0.981137  0.952556  0.982475  1.014134\n",
       "1     0.961773  0.954075  1.000977  1.012516\n",
       "2     0.976418  0.959950  1.004348  1.012822\n",
       "3     0.997731  0.964830  1.006085  1.013525\n",
       "4     0.995586  0.963184  1.039030  1.019582\n",
       "...        ...       ...       ...       ...\n",
       "1149  0.701544  0.738986  0.859484  0.971449\n",
       "1150  0.696051  0.758925  0.859755  0.973679\n",
       "1151  0.758008  0.822675  0.917373  0.979554\n",
       "1152  0.753222  0.805982  0.864973  0.972102\n",
       "1153  0.850299  0.891365  0.907568  0.981134\n",
       "\n",
       "[1154 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"submission_small_fields.csv\")\n",
    "\n",
    "# Load the second CSV file\n",
    "df2 = pd.read_csv(\"submission_small_fields_1d.csv\")\n",
    "\n",
    "# Remove the 'sample_index' column from both dataframes\n",
    "df1 = df1.drop(columns=['sample_index'])\n",
    "df2 = df2.drop(columns=['sample_index'])\n",
    "\n",
    "submission_df = pd.DataFrame(data=np.concatenate([df1 , df2],axis=0), columns=[\"P\", \"K\", \"Mg\", \"pH\"])\n",
    "submission_df.to_csv(\"submission_hybrid_knn.csv\", index_label=\"sample_index\")\n",
    "submission_df\n",
    "\n",
    "data = submission_df\n",
    "# Create new columns for labels and values\n",
    "labels = []\n",
    "values = []\n",
    "\n",
    "# Iterate through each row of the original data and expand it\n",
    "for i, row in data.iterrows():\n",
    "    for j, col in row.iteritems():\n",
    "        labels.append(f\"{i}_{j}\")\n",
    "        values.append(col)\n",
    "\n",
    "# Create a new DataFrame with the expanded data\n",
    "new_data = pd.DataFrame({\"Label\": labels, \"Value\": values})\n",
    "\n",
    "new_data.to_csv(\"submission_hybrid_knn.csv\", index=False)\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876da186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
