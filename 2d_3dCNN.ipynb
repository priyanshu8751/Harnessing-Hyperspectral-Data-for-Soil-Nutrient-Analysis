{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24003,
     "status": "ok",
     "timestamp": 1713107296644,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "DN2blKQnwQ7z",
    "outputId": "7dd3f88d-d635-4673-8f18-5c601bef6aaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7294,
     "status": "ok",
     "timestamp": 1713107308458,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "UPq5_78KnUSx"
   },
   "outputs": [],
   "source": [
    "# GENERAL UTILITIES\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from  tqdm.notebook import tqdm\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# MODEL DEVELOPMENT DEPENDENCIES\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1713107340024,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "AmeYFV4QxFsP"
   },
   "outputs": [],
   "source": [
    "def load_gt(file_path: str):\n",
    "    \"\"\"Load labels for train set from the ground truth file.\n",
    "    Args:\n",
    "        file_path (str): Path to the ground truth .csv file.\n",
    "    Returns:\n",
    "        [type]: 2D numpy array with soil properties levels\n",
    "    \"\"\"\n",
    "    gt_file = pd.read_csv(file_path)\n",
    "    labels = gt_file[[\"P\", \"K\", \"Mg\", \"pH\"]].values\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1713107340428,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "fghu379b39fa"
   },
   "outputs": [],
   "source": [
    "# use this if you want to divide the patches with unmasked pixel greater than threshold set to be 40, and maintain\n",
    "\n",
    "# the patch size to be smallest 11 x 11 constant for all patches, increasing the training data\n",
    "\n",
    "def load_data_div_patch(directory, gt_file_path):\n",
    "  datalist = []\n",
    "  masklist = []\n",
    "  augmented_data = []\n",
    "  augmented_label = []\n",
    "\n",
    "  labels = load_gt(gt_file_path)\n",
    "\n",
    "  all_files = np.array(\n",
    "      sorted(\n",
    "          glob(os.path.join(directory, \"*.npz\")),\n",
    "          key=lambda x: int(os.path.basename(x).replace(\".npz\", \"\")),\n",
    "      )\n",
    "  )\n",
    "\n",
    "#   all_files = all_files[1650:]\n",
    "  sum = 0\n",
    "  _min = 121\n",
    "\n",
    "  for idx, file_name in tqdm(enumerate(all_files),total=len(all_files), desc=\"Loading {} data ..\"\n",
    "                              .format(\"training\")):\n",
    "      # We load the data into memory as provided in the example notebook of the challenge\n",
    "      with np.load(file_name) as npz:\n",
    "          mask = npz[\"mask\"]\n",
    "          data = npz[\"data\"]\n",
    "          # masklist.append(mask)\n",
    "          # datalist.append(data)\n",
    "          sh = data.shape[1:]\n",
    "          edge = 11\n",
    "          # temp = 0\n",
    "          # for x in range(sh[0]):\n",
    "          #   for y in range(sh[1]):\n",
    "          #     if(mask[0][x][y] == True):\n",
    "          #       sum = sum + 1\n",
    "          #       temp = temp + 1\n",
    "          # _min = min(_min, temp)\n",
    "\n",
    "          appended = 0\n",
    "          for x in range(0, sh[0], edge):\n",
    "            for y in range(0, sh[1], edge):\n",
    "              if np.sum(mask[0, x : (x + edge), y : (y + edge)]) >= 40:\n",
    "                aug_data = data[:, x : (x + edge), y : (y + edge)]\n",
    "                augmented_data.append(aug_data)\n",
    "                augmented_label.append(labels[idx])\n",
    "                appended += 1\n",
    "          if appended == 0:\n",
    "            aug_data = data[:, (sh[0] - edge) / 2 : ((sh[0] - edge) / 2 + edge), (sh[1] - edge) / 2 : ((sh[1] - edge) / 2 + edge)]\n",
    "            augmented_data.append(aug_data)\n",
    "            augmented_label.append(labels[idx])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # print(_min, sum)\n",
    "  return augmented_data, augmented_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5DuWVJBnZqt"
   },
   "outputs": [],
   "source": [
    "# adds augmented data\n",
    "def load_data(directory, gt_file_path):\n",
    "    \"\"\"Load each cube, reduce its dimensionality and append to array.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Directory to either train or test set\n",
    "        gt_file_path (str): File path for the ground truth labels (expected CVS file)\n",
    "        is_train (boolean): Binary flag for setting loader for Train (TRUE) or Test (FALSE)\n",
    "        augment_constant (int): number of augmentation steps to randomly crop from the larger agricultural fields\n",
    "    Returns:\n",
    "        [type]: Tuple of lists composed of raw field (data , mask) pairs,\n",
    "                and if exists: (augmented data, augmented mask) pairs, and ground truth labels\n",
    "    \"\"\"\n",
    "\n",
    "    datalist = []\n",
    "    masklist = []\n",
    "\n",
    "    labels = load_gt(gt_file_path)\n",
    "\n",
    "    all_files = np.array(\n",
    "        sorted(\n",
    "            glob(os.path.join(directory, \"*.npz\")),\n",
    "            key=lambda x: int(os.path.basename(x).replace(\".npz\", \"\")),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    all_files = all_files[0:600]\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "\n",
    "    for idx, file_name in tqdm(enumerate(all_files),total=len(all_files), desc=\"Loading {} data ..\"\n",
    "                               .format(\"training\")):\n",
    "       # We load the data into memory as provided in the example notebook of the challenge\n",
    "        with np.load(file_name) as npz:\n",
    "            mask = npz[\"mask\"]\n",
    "            data = npz[\"data\"]\n",
    "            masklist.append(mask)\n",
    "            datalist.append(data)\n",
    "            continue\n",
    "            flag = True\n",
    "            ma = np.max(data, keepdims=False)\n",
    "            sh = data.shape[1:]\n",
    "            edge = 11\n",
    "            for x in range(sh[0] + 1 - edge):\n",
    "                for y in range(sh[1] + 1 - edge):\n",
    "                # Repeating 11x11 cropping 10 times does not mean we use all croppings:\n",
    "                # as seen in the Flag=False below at the end of the loop,\n",
    "                # when we reach at the good crop (not coinciding to the masked area) we stop searching\n",
    "\n",
    "                # Randomly cropping the fields with 11x11 size,\n",
    "                # and adding some noise to the cropped samples\n",
    "\n",
    "                # get crops having meaningful pixels, not zeros\n",
    "                  if np.sum(mask[0, x : (x + edge), y : (y + edge)]) >= 8:\n",
    "                      aug_data = data[:, x : (x + edge), y : (y + edge)]\n",
    "                      aug_mask = mask[:, x : (x + edge), y : (y + edge)]\n",
    "                      for k in range(150):\n",
    "                        for i in range(edge):\n",
    "                          for j in range(edge):\n",
    "                            if(aug_mask[k][i][j] == False):\n",
    "                              aug_data[k][i][j] = 0\n",
    "                      flag = False #break the loop when you have a meaningful crop\n",
    "                      break\n",
    "                  if not flag:\n",
    "                    break\n",
    "\n",
    "            if flag:\n",
    "              for x in range(sh[0] + 1 - edge):\n",
    "                for y in range(sh[1] + 1 - edge):\n",
    "                # Repeating 11x11 cropping 10 times does not mean we use all croppings:\n",
    "                # as seen in the Flag=False below at the end of the loop,\n",
    "                # when we reach at the good crop (not coinciding to the masked area) we stop searching\n",
    "\n",
    "                # Randomly cropping the fields with 11x11 size,\n",
    "                # and adding some noise to the cropped samples\n",
    "\n",
    "                # get crops having meaningful pixels, not zeros\n",
    "                  if np.sum(mask[0, x : (x + edge), y : (y + edge)]) >= 6:\n",
    "                    aug_data = data[:, x : (x + edge), y : (y + edge)]\n",
    "                    aug_mask = mask[:, x : (x + edge), y : (y + edge)]\n",
    "                    for k in range(150):\n",
    "                      for i in range(edge):\n",
    "                        for j in range(edge):\n",
    "                          if(aug_mask[k][i][j] == False):\n",
    "                            aug_data[k][i][j] = 0\n",
    "                    flag = False #break the loop when you have a meaningful crop\n",
    "                    count1 = count1 + 1\n",
    "                    break\n",
    "                  if not flag:\n",
    "                    break\n",
    "\n",
    "            # After having  11x11 croped sample, get another crop considering\n",
    "            # the minimum edge length: (min_edge,min_edge)\n",
    "            if flag:\n",
    "              count2 = count2 + 1\n",
    "              for k in range(150):\n",
    "                for i in range(sh[0]):\n",
    "                  for j in range(sh[1]):\n",
    "                    if(mask[k][i][j] == False):\n",
    "                      data[k][i][j] = 0\n",
    "              aug_data = cv2.resize(data, (edge, edge), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "            datalist.append(aug_data)\n",
    "\n",
    "\n",
    "    print(count1, count2)\n",
    "    return datalist, masklist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1713107570199,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "rgTeZInPQhtj"
   },
   "outputs": [],
   "source": [
    "def load_data_1d(directory, gt_file_path):\n",
    "  x_train = []\n",
    "  y_train = []\n",
    "  x_test = []\n",
    "  y_test = []\n",
    "\n",
    "  labels = load_gt(gt_file_path)\n",
    "\n",
    "  all_files = np.array(\n",
    "      sorted(\n",
    "          glob(os.path.join(directory, \"*.npz\")),\n",
    "          key=lambda x: int(os.path.basename(x).replace(\".npz\", \"\")),\n",
    "      )\n",
    "  )\n",
    "\n",
    "  all_files = all_files[1152:1153]\n",
    "  train_size = 0.8\n",
    "\n",
    "  for idx, file_name in tqdm(enumerate(all_files),total=len(all_files), desc=\"Loading {} data ..\"\n",
    "                              .format(\"training\")):\n",
    "      # We load the data into memory as provided in the example notebook of the challenge\n",
    "      with np.load(file_name) as npz:\n",
    "          mask = npz[\"mask\"]\n",
    "          data = npz[\"data\"]\n",
    "          sh = data.shape[1:]\n",
    "\n",
    "          augmented_data = []\n",
    "          for x in range(0, sh[0]):\n",
    "            for y in range(0, sh[1]):\n",
    "              if mask[0][x][y] == False:\n",
    "                augmented_data.append(data[:, x, y])\n",
    "\n",
    "          for i in range(len(augmented_data)):\n",
    "            if (i / len(augmented_data) < train_size):\n",
    "              x_train.append(augmented_data[i])\n",
    "              y_train.append(labels[idx])\n",
    "            else:\n",
    "              x_test.append(augmented_data[i])\n",
    "              y_test.append(labels[idx])\n",
    "\n",
    "  return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "12e820d687254b22a3b8eabbe9e306cc",
      "5b64039e080f49a3ad329d05e7914a8c",
      "dfcae9a7d415438382a7369ce13a06ef",
      "7c4f731ff4a2408192578eca04b8d210",
      "b1e99f6834be4271b09d127d10162e26",
      "a527ca861c844e61b32982dc8438a03b",
      "f3d3b3fde92147b79d76bc8c357c6cd9",
      "787c5f96e2c94a9eada3ad58c1416376",
      "9fc23f9f7dd84974ae9d78fcfbb3b825",
      "3dd0fe6a7f8e4e5c84ff0a23bd5019af",
      "935e7cc95acd40e991b519c9316343f2"
     ]
    },
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1713107572998,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "Xkuw1ymjpwL9",
    "outputId": "343fc619-0888-4582-85d1-dfcc62b91396"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e820d687254b22a3b8eabbe9e306cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading training data ..:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Please be sure that the directory and file locations are given correctly in your own system\n",
    "train_data_dir = \"/content/drive/MyDrive/BTP/train_data/train_data/train_data\"\n",
    "test_data_dir = \"/content/drive/MyDrive/BTP/test_data\"\n",
    "gt_data_path = \"/content/drive/MyDrive/BTP/train_data/train_data/train_gt.csv\"\n",
    "\n",
    "# Loading training raw data\n",
    "X_train, y_train = load_data(train_data_dir, gt_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1713107653941,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "as38wHjxKzF4",
    "outputId": "2151f5f1-1452-4b3b-88ac-41daae1871c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a4e349083a0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1d data\n",
    "plt.plot(X_train[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707820466624,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "GI_Bi25UBZyD",
    "outputId": "6f82889b-b8b1-4d1f-c486-b878f6bb6afd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DX2Q4HIYqVRe"
   },
   "outputs": [],
   "source": [
    "labels = load_gt(gt_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0H9YOOLddZyT"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(200):\n",
    "  d1 = []\n",
    "  for j in range(150):\n",
    "    a = cv2.resize(X_train[i][j], (11, 11), interpolation=cv2.INTER_LINEAR)\n",
    "    d1.append(a.astype(float))\n",
    "  d1 = np.array(d1)\n",
    "  X.append(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJUD6YxvlXwB"
   },
   "outputs": [],
   "source": [
    "\n",
    "M = []\n",
    "for i in range(200):\n",
    "  d1 = []\n",
    "  for j in range(150):\n",
    "    uint = M_train[i][j].astype(np.uint8) * 255\n",
    "    a = cv2.resize(uint, (11, 11), interpolation=cv2.INTER_AREA)\n",
    "    d1.append(a)\n",
    "  d1 = np.array(d1)\n",
    "  M.append(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsQzrpItmW1G"
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "M = np.array(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldBJOQxWob3i"
   },
   "outputs": [],
   "source": [
    "X_train1 = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAExuTOWA8m1"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7KoOJbhIwti"
   },
   "outputs": [],
   "source": [
    "M_train = np.array(M_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1707469936252,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "6o2mxHVboOxm",
    "outputId": "291c44c0-b192-4523-b9e6-90886839d1f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBnDaQtKo-cg"
   },
   "outputs": [],
   "source": [
    "X1 = X * M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1707290598721,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "dsRx3xv0cvsB",
    "outputId": "e529bd4c-3cd4-4e55-d546-95494ed537a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884850.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbefbfMPcyqx"
   },
   "outputs": [],
   "source": [
    "X1 = X1 / 884850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e57fb_AF-CSr"
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (600, 11, 11, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707470003670,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "YND8H2BcpJk6",
    "outputId": "ae2522d6-4dba-4a4f-bf37-101a6e281c15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 11, 11, 150)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vD8-TFI1S5uu"
   },
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "  for j in range(11):\n",
    "    for k in range(11):\n",
    "      for l in range(150):\n",
    "        if(M_train[i][j][k][l] == False):\n",
    "          X_train[i][j][k][l] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 1094,
     "status": "ok",
     "timestamp": 1707472724723,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "AVSdb6nw1Wk6",
    "outputId": "982d800b-115c-4c41-bb7d-bb35e3772697"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb60b8630d0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmuif-J2jfaC"
   },
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHtrZ9WmjhwD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32 , (1, 1), activation='relu', input_shape=(11, 11, 150)))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(64 , (1, 1), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFD3VgpZnK6p"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54uSs3R1ckHB"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202993,
     "status": "ok",
     "timestamp": 1711334625237,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "LIb45rttn3fY",
    "outputId": "d0943385-8847-47ce-b456-ad92480a58af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "50/50 [==============================] - 1s 9ms/step - loss: 446078.1875 - mae: 246.3151 - val_loss: 5713.1465 - val_mae: 54.1580\n",
      "Epoch 2/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 2506.2881 - mae: 37.8234 - val_loss: 4697.9653 - val_mae: 48.0838\n",
      "Epoch 3/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2250.2466 - mae: 36.3061 - val_loss: 4161.3730 - val_mae: 41.0403\n",
      "Epoch 4/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1881.8643 - mae: 31.4220 - val_loss: 4266.6338 - val_mae: 43.4910\n",
      "Epoch 5/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2026.6941 - mae: 33.6048 - val_loss: 4135.5840 - val_mae: 42.7161\n",
      "Epoch 6/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1782.1323 - mae: 30.4291 - val_loss: 4304.5918 - val_mae: 41.2859\n",
      "Epoch 7/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1795.2758 - mae: 30.5837 - val_loss: 4170.8667 - val_mae: 42.1392\n",
      "Epoch 8/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 2129.3687 - mae: 34.0319 - val_loss: 4641.8721 - val_mae: 46.5756\n",
      "Epoch 9/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2086.0901 - mae: 33.8995 - val_loss: 4106.8818 - val_mae: 43.8238\n",
      "Epoch 10/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2387.1147 - mae: 37.6878 - val_loss: 5063.5034 - val_mae: 46.3296\n",
      "Epoch 11/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2029.4900 - mae: 34.3767 - val_loss: 5607.6587 - val_mae: 45.1430\n",
      "Epoch 12/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1720.8577 - mae: 29.7688 - val_loss: 4283.3613 - val_mae: 42.5905\n",
      "Epoch 13/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1805.1003 - mae: 31.0825 - val_loss: 4118.5752 - val_mae: 42.9913\n",
      "Epoch 14/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1733.1384 - mae: 30.0800 - val_loss: 4126.7329 - val_mae: 42.3521\n",
      "Epoch 15/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1759.1089 - mae: 31.0362 - val_loss: 4413.0747 - val_mae: 41.6017\n",
      "Epoch 16/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1679.0205 - mae: 29.5134 - val_loss: 4216.4282 - val_mae: 40.9376\n",
      "Epoch 17/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1575.4399 - mae: 28.3604 - val_loss: 4793.8154 - val_mae: 47.3087\n",
      "Epoch 18/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1685.2527 - mae: 30.2245 - val_loss: 4879.5020 - val_mae: 46.7124\n",
      "Epoch 19/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1684.5171 - mae: 29.2107 - val_loss: 4530.0073 - val_mae: 42.0292\n",
      "Epoch 20/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1935.9861 - mae: 32.7270 - val_loss: 4792.1611 - val_mae: 45.3106\n",
      "Epoch 21/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 1726.6384 - mae: 30.3984 - val_loss: 4228.0718 - val_mae: 43.5218\n",
      "Epoch 22/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 1681.6431 - mae: 30.0016 - val_loss: 5322.1279 - val_mae: 49.1487\n",
      "Epoch 23/500\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 1638.9617 - mae: 30.2325 - val_loss: 4788.7427 - val_mae: 43.1666\n",
      "Epoch 24/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 1612.7510 - mae: 29.7562 - val_loss: 4398.4951 - val_mae: 41.6184\n",
      "Epoch 25/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1393.0359 - mae: 26.4730 - val_loss: 4550.2373 - val_mae: 43.7035\n",
      "Epoch 26/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1321.4058 - mae: 25.5903 - val_loss: 4394.6572 - val_mae: 42.2455\n",
      "Epoch 27/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1479.2607 - mae: 27.8995 - val_loss: 5090.2871 - val_mae: 45.1932\n",
      "Epoch 28/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1343.9062 - mae: 26.2234 - val_loss: 4533.3638 - val_mae: 43.6016\n",
      "Epoch 29/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1392.0197 - mae: 26.9561 - val_loss: 4930.2886 - val_mae: 45.8230\n",
      "Epoch 30/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1306.9932 - mae: 25.7565 - val_loss: 4525.4668 - val_mae: 43.3330\n",
      "Epoch 31/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2440.5483 - mae: 32.6371 - val_loss: 8922.9053 - val_mae: 69.9010\n",
      "Epoch 32/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1965.3589 - mae: 32.1851 - val_loss: 5235.4907 - val_mae: 44.8876\n",
      "Epoch 33/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1974.7220 - mae: 30.1126 - val_loss: 4612.8975 - val_mae: 42.1827\n",
      "Epoch 34/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1455.3900 - mae: 26.9375 - val_loss: 4532.6060 - val_mae: 41.2340\n",
      "Epoch 35/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1386.7228 - mae: 25.8935 - val_loss: 4638.0854 - val_mae: 42.5724\n",
      "Epoch 36/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1443.1567 - mae: 26.7571 - val_loss: 4583.9883 - val_mae: 41.3836\n",
      "Epoch 37/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1302.2361 - mae: 24.9496 - val_loss: 4373.7314 - val_mae: 41.5010\n",
      "Epoch 38/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1324.6971 - mae: 25.6161 - val_loss: 4519.1470 - val_mae: 41.5398\n",
      "Epoch 39/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1305.3707 - mae: 25.4103 - val_loss: 5355.5439 - val_mae: 44.8630\n",
      "Epoch 40/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1278.1277 - mae: 25.0960 - val_loss: 4407.3682 - val_mae: 41.7068\n",
      "Epoch 41/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1250.4061 - mae: 24.8179 - val_loss: 4615.3711 - val_mae: 41.7364\n",
      "Epoch 42/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1186.5680 - mae: 24.1012 - val_loss: 4827.5786 - val_mae: 42.5631\n",
      "Epoch 43/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1274.1747 - mae: 25.3545 - val_loss: 4873.4854 - val_mae: 42.7405\n",
      "Epoch 44/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1266.0315 - mae: 25.3700 - val_loss: 4789.9512 - val_mae: 45.1805\n",
      "Epoch 45/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1227.6061 - mae: 24.5599 - val_loss: 4526.5049 - val_mae: 41.7867\n",
      "Epoch 46/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1118.4769 - mae: 23.2578 - val_loss: 4838.1289 - val_mae: 46.0275\n",
      "Epoch 47/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1188.5753 - mae: 24.2824 - val_loss: 4538.5933 - val_mae: 42.2874\n",
      "Epoch 48/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1105.0698 - mae: 23.2079 - val_loss: 4721.1816 - val_mae: 45.0939\n",
      "Epoch 49/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1159.7731 - mae: 24.1347 - val_loss: 4952.2148 - val_mae: 43.6780\n",
      "Epoch 50/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1091.1377 - mae: 23.0851 - val_loss: 4977.2490 - val_mae: 43.3908\n",
      "Epoch 51/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1115.0454 - mae: 23.6072 - val_loss: 4836.4062 - val_mae: 43.2428\n",
      "Epoch 52/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1020.5634 - mae: 21.8379 - val_loss: 4886.0049 - val_mae: 43.4568\n",
      "Epoch 53/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 1156.6151 - mae: 23.7475 - val_loss: 4675.9922 - val_mae: 43.7312\n",
      "Epoch 54/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 1096.5886 - mae: 22.9540 - val_loss: 4892.4312 - val_mae: 44.3307\n",
      "Epoch 55/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 1039.6047 - mae: 22.4537 - val_loss: 5106.4536 - val_mae: 45.5711\n",
      "Epoch 56/500\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 1127.8989 - mae: 23.9741 - val_loss: 4952.0254 - val_mae: 44.5155\n",
      "Epoch 57/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1073.8492 - mae: 22.7436 - val_loss: 5301.3921 - val_mae: 44.4659\n",
      "Epoch 58/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 965.5349 - mae: 21.2538 - val_loss: 5019.7251 - val_mae: 43.6267\n",
      "Epoch 59/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1042.8081 - mae: 22.6737 - val_loss: 5064.4824 - val_mae: 43.3139\n",
      "Epoch 60/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 993.2567 - mae: 21.7966 - val_loss: 5026.9053 - val_mae: 44.7738\n",
      "Epoch 61/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 987.9204 - mae: 21.7800 - val_loss: 5360.7227 - val_mae: 46.0777\n",
      "Epoch 62/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 939.2319 - mae: 21.0723 - val_loss: 5213.4946 - val_mae: 44.3323\n",
      "Epoch 63/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 916.9659 - mae: 20.8647 - val_loss: 4894.8032 - val_mae: 43.2111\n",
      "Epoch 64/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 897.9543 - mae: 20.3750 - val_loss: 5311.6118 - val_mae: 45.3012\n",
      "Epoch 65/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 872.8738 - mae: 20.5298 - val_loss: 4901.8872 - val_mae: 43.4890\n",
      "Epoch 66/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 846.0304 - mae: 19.7600 - val_loss: 4838.2295 - val_mae: 44.4268\n",
      "Epoch 67/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 810.3692 - mae: 19.3814 - val_loss: 5225.3369 - val_mae: 44.1445\n",
      "Epoch 68/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 846.9485 - mae: 20.0018 - val_loss: 5222.0151 - val_mae: 44.7678\n",
      "Epoch 69/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 864.2424 - mae: 20.3668 - val_loss: 5252.9971 - val_mae: 45.1195\n",
      "Epoch 70/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 815.1894 - mae: 19.3400 - val_loss: 5208.9736 - val_mae: 44.6910\n",
      "Epoch 71/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 798.3600 - mae: 19.4031 - val_loss: 5450.9033 - val_mae: 45.3849\n",
      "Epoch 72/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 959.0324 - mae: 21.5686 - val_loss: 4946.3506 - val_mae: 43.3688\n",
      "Epoch 73/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 906.4540 - mae: 21.0003 - val_loss: 5063.9683 - val_mae: 44.9729\n",
      "Epoch 74/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 911.1782 - mae: 21.0251 - val_loss: 5845.3018 - val_mae: 49.0484\n",
      "Epoch 75/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 884.0670 - mae: 20.5424 - val_loss: 9688.1904 - val_mae: 81.9338\n",
      "Epoch 76/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1631.6764 - mae: 28.6797 - val_loss: 4971.5386 - val_mae: 43.2082\n",
      "Epoch 77/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1198.3430 - mae: 23.9763 - val_loss: 4807.3008 - val_mae: 44.2510\n",
      "Epoch 78/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1051.9095 - mae: 22.6511 - val_loss: 5247.8379 - val_mae: 44.7711\n",
      "Epoch 79/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 997.3197 - mae: 21.6256 - val_loss: 5088.8960 - val_mae: 44.2034\n",
      "Epoch 80/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 882.0972 - mae: 20.1548 - val_loss: 5375.6187 - val_mae: 45.2720\n",
      "Epoch 81/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 769.0999 - mae: 18.6506 - val_loss: 5145.5884 - val_mae: 45.0142\n",
      "Epoch 82/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 904.7985 - mae: 20.9311 - val_loss: 5857.3081 - val_mae: 47.5495\n",
      "Epoch 83/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1043.0305 - mae: 22.4900 - val_loss: 5320.8096 - val_mae: 45.7555\n",
      "Epoch 84/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 824.4754 - mae: 19.8191 - val_loss: 5405.0879 - val_mae: 47.0566\n",
      "Epoch 85/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1160.7249 - mae: 23.6656 - val_loss: 4804.2246 - val_mae: 44.0860\n",
      "Epoch 86/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 980.1092 - mae: 21.2656 - val_loss: 5242.7920 - val_mae: 45.0732\n",
      "Epoch 87/500\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 964.7349 - mae: 21.3411 - val_loss: 5612.9707 - val_mae: 46.6453\n",
      "Epoch 88/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 939.9229 - mae: 20.9387 - val_loss: 5479.7119 - val_mae: 44.8987\n",
      "Epoch 89/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 814.4128 - mae: 19.4143 - val_loss: 5136.8071 - val_mae: 44.7745\n",
      "Epoch 90/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 735.0089 - mae: 18.4601 - val_loss: 5432.8345 - val_mae: 46.1503\n",
      "Epoch 91/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 714.2929 - mae: 17.8570 - val_loss: 5343.6250 - val_mae: 45.4350\n",
      "Epoch 92/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 683.9671 - mae: 17.6515 - val_loss: 5301.5068 - val_mae: 45.1789\n",
      "Epoch 93/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 732.8973 - mae: 18.5557 - val_loss: 5605.0444 - val_mae: 47.0852\n",
      "Epoch 94/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 781.0865 - mae: 19.1673 - val_loss: 5316.6577 - val_mae: 45.0500\n",
      "Epoch 95/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 803.8999 - mae: 19.4262 - val_loss: 5912.8901 - val_mae: 48.9068\n",
      "Epoch 96/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1058.1656 - mae: 22.7031 - val_loss: 5593.6621 - val_mae: 47.9248\n",
      "Epoch 97/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 794.3309 - mae: 19.6650 - val_loss: 5429.3579 - val_mae: 47.4222\n",
      "Epoch 98/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 852.9554 - mae: 20.0230 - val_loss: 5440.3779 - val_mae: 45.8517\n",
      "Epoch 99/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 809.6711 - mae: 19.4125 - val_loss: 5600.1523 - val_mae: 46.9897\n",
      "Epoch 100/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 758.4518 - mae: 18.7547 - val_loss: 5323.3936 - val_mae: 45.4743\n",
      "Epoch 101/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 805.9515 - mae: 19.6171 - val_loss: 5251.0288 - val_mae: 44.3589\n",
      "Epoch 102/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 820.4828 - mae: 19.8042 - val_loss: 5596.0532 - val_mae: 46.6379\n",
      "Epoch 103/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 751.4280 - mae: 18.5362 - val_loss: 5270.7251 - val_mae: 45.8722\n",
      "Epoch 104/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 999.7426 - mae: 21.8979 - val_loss: 6036.3921 - val_mae: 47.2123\n",
      "Epoch 105/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 875.8848 - mae: 20.5059 - val_loss: 6001.5938 - val_mae: 46.8090\n",
      "Epoch 106/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1007.8378 - mae: 21.9281 - val_loss: 5643.1167 - val_mae: 45.6853\n",
      "Epoch 107/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 847.9994 - mae: 20.1724 - val_loss: 5329.2144 - val_mae: 45.4722\n",
      "Epoch 108/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 824.9930 - mae: 20.1828 - val_loss: 5856.8242 - val_mae: 46.9140\n",
      "Epoch 109/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 818.3793 - mae: 19.7411 - val_loss: 5124.3848 - val_mae: 44.1087\n",
      "Epoch 110/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 832.5344 - mae: 20.2429 - val_loss: 5341.4067 - val_mae: 45.1321\n",
      "Epoch 111/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 736.8920 - mae: 18.7911 - val_loss: 5941.9263 - val_mae: 47.3588\n",
      "Epoch 112/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 702.1562 - mae: 17.8564 - val_loss: 6023.9746 - val_mae: 49.0274\n",
      "Epoch 113/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 651.9345 - mae: 17.6873 - val_loss: 6074.8867 - val_mae: 49.5333\n",
      "Epoch 114/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 646.3887 - mae: 17.2324 - val_loss: 6057.7183 - val_mae: 48.6038\n",
      "Epoch 115/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 657.0938 - mae: 17.4427 - val_loss: 5669.4258 - val_mae: 46.7256\n",
      "Epoch 116/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 683.9136 - mae: 17.9913 - val_loss: 5459.5107 - val_mae: 47.0228\n",
      "Epoch 117/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 757.6440 - mae: 18.7849 - val_loss: 5660.5708 - val_mae: 47.4707\n",
      "Epoch 118/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 879.4927 - mae: 20.5738 - val_loss: 5324.4712 - val_mae: 47.5545\n",
      "Epoch 119/500\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 1004.1794 - mae: 21.9260 - val_loss: 5110.2573 - val_mae: 46.0647\n",
      "Epoch 120/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 1401.2297 - mae: 26.0212 - val_loss: 5314.7627 - val_mae: 45.4942\n",
      "Epoch 121/500\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 1073.6604 - mae: 22.6575 - val_loss: 5701.1763 - val_mae: 46.8233\n",
      "Epoch 122/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 761.4817 - mae: 18.8819 - val_loss: 6131.7026 - val_mae: 48.6024\n",
      "Epoch 123/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 793.8395 - mae: 19.1941 - val_loss: 5512.9707 - val_mae: 46.4690\n",
      "Epoch 124/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 796.6483 - mae: 19.5083 - val_loss: 5904.8481 - val_mae: 47.6581\n",
      "Epoch 125/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 657.5508 - mae: 17.3533 - val_loss: 5215.7905 - val_mae: 44.9627\n",
      "Epoch 126/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 690.6663 - mae: 17.6748 - val_loss: 5943.3237 - val_mae: 47.2674\n",
      "Epoch 127/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 630.9782 - mae: 17.0091 - val_loss: 6242.9746 - val_mae: 48.5352\n",
      "Epoch 128/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 667.6761 - mae: 17.5168 - val_loss: 5787.1973 - val_mae: 46.5865\n",
      "Epoch 129/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 683.8451 - mae: 17.4057 - val_loss: 6085.4800 - val_mae: 49.3279\n",
      "Epoch 130/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 813.6617 - mae: 19.6543 - val_loss: 5783.4351 - val_mae: 47.1415\n",
      "Epoch 131/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 703.8370 - mae: 18.1770 - val_loss: 5857.8521 - val_mae: 46.7847\n",
      "Epoch 132/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 581.6249 - mae: 16.1840 - val_loss: 6022.9258 - val_mae: 47.8026\n",
      "Epoch 133/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 602.5330 - mae: 16.3383 - val_loss: 5435.0894 - val_mae: 45.0385\n",
      "Epoch 134/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 587.2383 - mae: 16.1727 - val_loss: 5954.3652 - val_mae: 47.1961\n",
      "Epoch 135/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 669.3179 - mae: 17.2029 - val_loss: 6184.5542 - val_mae: 48.1801\n",
      "Epoch 136/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 694.8873 - mae: 17.8669 - val_loss: 5889.0049 - val_mae: 47.4011\n",
      "Epoch 137/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 652.0712 - mae: 16.9947 - val_loss: 5753.9336 - val_mae: 45.8559\n",
      "Epoch 138/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 771.4423 - mae: 18.3343 - val_loss: 5320.2432 - val_mae: 44.9298\n",
      "Epoch 139/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 813.4398 - mae: 18.8858 - val_loss: 5242.2637 - val_mae: 43.7352\n",
      "Epoch 140/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 694.6272 - mae: 17.4317 - val_loss: 6032.4849 - val_mae: 47.8611\n",
      "Epoch 141/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 715.2202 - mae: 17.4881 - val_loss: 5597.9268 - val_mae: 46.4134\n",
      "Epoch 142/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 770.7205 - mae: 18.1003 - val_loss: 5545.6045 - val_mae: 45.1310\n",
      "Epoch 143/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 837.4701 - mae: 19.1366 - val_loss: 5150.6011 - val_mae: 44.2606\n",
      "Epoch 144/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 779.3685 - mae: 18.3945 - val_loss: 5086.0723 - val_mae: 43.3284\n",
      "Epoch 145/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 738.8639 - mae: 17.6854 - val_loss: 6160.6094 - val_mae: 46.7499\n",
      "Epoch 146/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 601.6877 - mae: 15.9970 - val_loss: 6120.6362 - val_mae: 48.1559\n",
      "Epoch 147/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 917.4771 - mae: 19.9842 - val_loss: 5745.0220 - val_mae: 46.7290\n",
      "Epoch 148/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 681.7892 - mae: 17.0020 - val_loss: 5581.3496 - val_mae: 46.2287\n",
      "Epoch 149/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 740.1101 - mae: 17.4670 - val_loss: 6737.8906 - val_mae: 49.1108\n",
      "Epoch 150/500\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 718.3985 - mae: 17.5534 - val_loss: 6901.8911 - val_mae: 49.6429\n",
      "Epoch 151/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 810.5171 - mae: 18.4119 - val_loss: 5548.2837 - val_mae: 45.8985\n",
      "Epoch 152/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 625.9386 - mae: 16.4569 - val_loss: 6495.8149 - val_mae: 48.0020\n",
      "Epoch 153/500\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 566.1143 - mae: 15.3229 - val_loss: 6055.1475 - val_mae: 47.6311\n",
      "Epoch 154/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 618.3459 - mae: 15.7376 - val_loss: 6312.4390 - val_mae: 47.8857\n",
      "Epoch 155/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 780.0595 - mae: 18.2533 - val_loss: 5739.0098 - val_mae: 45.3994\n",
      "Epoch 156/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 554.9113 - mae: 15.0089 - val_loss: 6039.0527 - val_mae: 45.9816\n",
      "Epoch 157/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 541.0610 - mae: 14.5991 - val_loss: 6028.6274 - val_mae: 47.6315\n",
      "Epoch 158/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 999.4808 - mae: 21.1055 - val_loss: 6073.3662 - val_mae: 46.1989\n",
      "Epoch 159/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 907.9504 - mae: 19.5431 - val_loss: 5509.1187 - val_mae: 45.2651\n",
      "Epoch 160/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 853.5474 - mae: 19.1221 - val_loss: 6615.0186 - val_mae: 48.9879\n",
      "Epoch 161/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 934.3889 - mae: 19.9457 - val_loss: 6327.1431 - val_mae: 47.3599\n",
      "Epoch 162/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 931.1802 - mae: 20.2016 - val_loss: 5590.2861 - val_mae: 45.2296\n",
      "Epoch 163/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 705.8512 - mae: 17.0550 - val_loss: 5666.7217 - val_mae: 46.1995\n",
      "Epoch 164/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 928.5795 - mae: 19.9273 - val_loss: 6177.8164 - val_mae: 47.2391\n",
      "Epoch 165/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 635.3373 - mae: 16.2892 - val_loss: 6350.6006 - val_mae: 47.3933\n",
      "Epoch 166/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 678.5237 - mae: 16.7593 - val_loss: 5413.5908 - val_mae: 44.7937\n",
      "Epoch 167/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 577.0818 - mae: 15.3069 - val_loss: 5837.9932 - val_mae: 46.1978\n",
      "Epoch 168/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 703.4041 - mae: 17.1687 - val_loss: 5537.0220 - val_mae: 43.4157\n",
      "Epoch 169/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 733.3030 - mae: 17.4635 - val_loss: 5533.1367 - val_mae: 44.7168\n",
      "Epoch 170/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 534.7658 - mae: 14.8067 - val_loss: 5407.1895 - val_mae: 45.6318\n",
      "Epoch 171/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 678.0863 - mae: 16.9661 - val_loss: 5741.3262 - val_mae: 45.3969\n",
      "Epoch 172/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 607.9666 - mae: 15.7090 - val_loss: 6529.9136 - val_mae: 47.8541\n",
      "Epoch 173/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 787.6260 - mae: 18.4067 - val_loss: 5600.3882 - val_mae: 43.9457\n",
      "Epoch 174/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 915.5302 - mae: 19.4821 - val_loss: 4658.8203 - val_mae: 42.0453\n",
      "Epoch 175/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1125.0688 - mae: 21.9748 - val_loss: 7026.2383 - val_mae: 51.0583\n",
      "Epoch 176/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1041.8054 - mae: 21.0136 - val_loss: 5395.0151 - val_mae: 47.1947\n",
      "Epoch 177/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1309.7279 - mae: 23.6941 - val_loss: 5126.1880 - val_mae: 42.7718\n",
      "Epoch 178/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1490.8816 - mae: 25.3283 - val_loss: 5132.8110 - val_mae: 42.1074\n",
      "Epoch 179/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1200.1542 - mae: 22.2376 - val_loss: 5182.3804 - val_mae: 43.2100\n",
      "Epoch 180/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1086.8058 - mae: 21.3142 - val_loss: 5554.8281 - val_mae: 44.0227\n",
      "Epoch 181/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 872.6964 - mae: 19.0789 - val_loss: 5988.8667 - val_mae: 46.4310\n",
      "Epoch 182/500\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 888.5361 - mae: 19.4467 - val_loss: 5228.6724 - val_mae: 42.9883\n",
      "Epoch 183/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 962.4127 - mae: 20.5923 - val_loss: 4990.6357 - val_mae: 42.5982\n",
      "Epoch 184/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 790.3767 - mae: 18.4062 - val_loss: 5819.5864 - val_mae: 44.9570\n",
      "Epoch 185/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 774.5831 - mae: 18.0555 - val_loss: 6117.4458 - val_mae: 46.4971\n",
      "Epoch 186/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 662.8063 - mae: 16.3284 - val_loss: 5854.6768 - val_mae: 45.1571\n",
      "Epoch 187/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 584.1448 - mae: 15.4007 - val_loss: 5866.8691 - val_mae: 46.2492\n",
      "Epoch 188/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 558.3251 - mae: 15.0746 - val_loss: 5746.2383 - val_mae: 45.7973\n",
      "Epoch 189/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 594.0789 - mae: 15.4852 - val_loss: 5632.9829 - val_mae: 44.6169\n",
      "Epoch 190/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 590.2504 - mae: 15.5158 - val_loss: 5920.8711 - val_mae: 44.5508\n",
      "Epoch 191/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 627.4176 - mae: 16.2041 - val_loss: 6077.9644 - val_mae: 46.9002\n",
      "Epoch 192/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 629.8094 - mae: 16.1971 - val_loss: 5847.4463 - val_mae: 45.5317\n",
      "Epoch 193/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 495.0478 - mae: 13.9504 - val_loss: 6410.6611 - val_mae: 46.9402\n",
      "Epoch 194/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 746.7873 - mae: 17.6840 - val_loss: 5316.7061 - val_mae: 44.0504\n",
      "Epoch 195/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 813.5328 - mae: 18.6903 - val_loss: 6230.1006 - val_mae: 47.4743\n",
      "Epoch 196/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 849.5957 - mae: 19.0891 - val_loss: 6421.9727 - val_mae: 47.8208\n",
      "Epoch 197/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 940.7520 - mae: 20.0595 - val_loss: 5433.0195 - val_mae: 43.2635\n",
      "Epoch 198/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 802.7441 - mae: 18.1501 - val_loss: 6700.6689 - val_mae: 49.9278\n",
      "Epoch 199/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 740.7428 - mae: 17.6918 - val_loss: 5856.6504 - val_mae: 45.3835\n",
      "Epoch 200/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 564.0953 - mae: 14.8739 - val_loss: 5722.2969 - val_mae: 45.8774\n",
      "Epoch 201/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 551.2165 - mae: 14.9896 - val_loss: 6148.3027 - val_mae: 46.4144\n",
      "Epoch 202/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 663.8409 - mae: 16.5495 - val_loss: 5341.6650 - val_mae: 43.8252\n",
      "Epoch 203/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 540.9578 - mae: 14.4378 - val_loss: 5899.7598 - val_mae: 44.8943\n",
      "Epoch 204/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 718.7731 - mae: 17.4257 - val_loss: 6736.8237 - val_mae: 49.4538\n",
      "Epoch 205/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 578.0304 - mae: 15.2342 - val_loss: 5472.6543 - val_mae: 44.5272\n",
      "Epoch 206/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 755.9138 - mae: 17.6341 - val_loss: 5878.8184 - val_mae: 45.0641\n",
      "Epoch 207/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 737.1501 - mae: 17.4496 - val_loss: 5279.3921 - val_mae: 43.8769\n",
      "Epoch 208/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 680.5553 - mae: 17.1078 - val_loss: 5979.0850 - val_mae: 45.4347\n",
      "Epoch 209/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 598.0559 - mae: 15.5283 - val_loss: 5843.1650 - val_mae: 44.6726\n",
      "Epoch 210/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 633.2071 - mae: 16.2643 - val_loss: 6583.1758 - val_mae: 47.5431\n",
      "Epoch 211/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 821.3031 - mae: 18.3981 - val_loss: 6861.7764 - val_mae: 52.7284\n",
      "Epoch 212/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1052.4069 - mae: 21.0499 - val_loss: 6042.9800 - val_mae: 45.6766\n",
      "Epoch 213/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 860.5648 - mae: 19.1256 - val_loss: 6048.6606 - val_mae: 46.3438\n",
      "Epoch 214/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 1091.1764 - mae: 22.0647 - val_loss: 5079.0298 - val_mae: 41.7753\n",
      "Epoch 215/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 822.3028 - mae: 18.3566 - val_loss: 5646.3594 - val_mae: 43.6962\n",
      "Epoch 216/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 621.3235 - mae: 15.9017 - val_loss: 6081.8105 - val_mae: 48.8346\n",
      "Epoch 217/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 699.0250 - mae: 17.2787 - val_loss: 5621.8286 - val_mae: 45.1397\n",
      "Epoch 218/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 629.0394 - mae: 16.1671 - val_loss: 6574.5698 - val_mae: 48.5927\n",
      "Epoch 219/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 492.0654 - mae: 14.0721 - val_loss: 5957.1318 - val_mae: 46.0051\n",
      "Epoch 220/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 572.7727 - mae: 15.7167 - val_loss: 5831.9756 - val_mae: 44.4972\n",
      "Epoch 221/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 607.3277 - mae: 16.0664 - val_loss: 5771.8188 - val_mae: 45.2573\n",
      "Epoch 222/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 602.3008 - mae: 15.7199 - val_loss: 5351.5879 - val_mae: 45.1743\n",
      "Epoch 223/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 664.4235 - mae: 16.5702 - val_loss: 5830.4424 - val_mae: 47.1720\n",
      "Epoch 224/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 806.0909 - mae: 18.3255 - val_loss: 5490.2432 - val_mae: 44.0719\n",
      "Epoch 225/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 634.0483 - mae: 16.1573 - val_loss: 5797.9556 - val_mae: 45.6522\n",
      "Epoch 226/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1172.2148 - mae: 22.2702 - val_loss: 6087.8745 - val_mae: 46.7672\n",
      "Epoch 227/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1190.2035 - mae: 22.9005 - val_loss: 6007.0532 - val_mae: 46.7886\n",
      "Epoch 228/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1072.9750 - mae: 21.0172 - val_loss: 5349.4580 - val_mae: 44.0156\n",
      "Epoch 229/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1082.4128 - mae: 21.5274 - val_loss: 5609.5156 - val_mae: 43.6835\n",
      "Epoch 230/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 725.1843 - mae: 17.2733 - val_loss: 5791.9780 - val_mae: 45.3445\n",
      "Epoch 231/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 747.6710 - mae: 17.8531 - val_loss: 5580.2227 - val_mae: 44.8071\n",
      "Epoch 232/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 726.1641 - mae: 17.8868 - val_loss: 5235.8389 - val_mae: 43.4299\n",
      "Epoch 233/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 575.6704 - mae: 15.3466 - val_loss: 5853.3130 - val_mae: 45.2329\n",
      "Epoch 234/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 610.2273 - mae: 15.8355 - val_loss: 5617.2119 - val_mae: 45.7164\n",
      "Epoch 235/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 786.3833 - mae: 18.7599 - val_loss: 5711.1030 - val_mae: 44.4916\n",
      "Epoch 236/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 674.0555 - mae: 17.1121 - val_loss: 6663.1743 - val_mae: 48.6740\n",
      "Epoch 237/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 561.7766 - mae: 14.9262 - val_loss: 5593.9468 - val_mae: 46.0096\n",
      "Epoch 238/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 653.3497 - mae: 16.6202 - val_loss: 5835.6758 - val_mae: 46.3111\n",
      "Epoch 239/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 589.9832 - mae: 15.6762 - val_loss: 5537.3398 - val_mae: 43.7903\n",
      "Epoch 240/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 730.9600 - mae: 17.5092 - val_loss: 6395.8770 - val_mae: 46.8848\n",
      "Epoch 241/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 682.4191 - mae: 16.8454 - val_loss: 6137.9692 - val_mae: 47.0736\n",
      "Epoch 242/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 598.8713 - mae: 15.6171 - val_loss: 6180.0938 - val_mae: 45.3786\n",
      "Epoch 243/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 543.3162 - mae: 14.7845 - val_loss: 5768.1675 - val_mae: 46.1189\n",
      "Epoch 244/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 561.8162 - mae: 15.2750 - val_loss: 5922.9932 - val_mae: 44.6557\n",
      "Epoch 245/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 755.9780 - mae: 18.0069 - val_loss: 5400.2158 - val_mae: 44.7002\n",
      "Epoch 246/500\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 811.2375 - mae: 18.7991 - val_loss: 5742.3457 - val_mae: 44.3779\n",
      "Epoch 247/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 794.7849 - mae: 18.5080 - val_loss: 5691.9507 - val_mae: 45.1333\n",
      "Epoch 248/500\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 740.2344 - mae: 17.3407 - val_loss: 5681.3140 - val_mae: 45.3130\n",
      "Epoch 249/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 849.4638 - mae: 18.9708 - val_loss: 5594.0269 - val_mae: 45.1272\n",
      "Epoch 250/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 645.1536 - mae: 16.3493 - val_loss: 6139.4404 - val_mae: 46.9819\n",
      "Epoch 251/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 652.9330 - mae: 16.6480 - val_loss: 6557.6025 - val_mae: 48.8682\n",
      "Epoch 252/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 707.8145 - mae: 16.7429 - val_loss: 5449.5811 - val_mae: 44.3276\n",
      "Epoch 253/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 686.4035 - mae: 16.8665 - val_loss: 5789.9268 - val_mae: 44.8982\n",
      "Epoch 254/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 568.5559 - mae: 14.9531 - val_loss: 6311.0562 - val_mae: 46.5969\n",
      "Epoch 255/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 557.9027 - mae: 15.2415 - val_loss: 5493.9531 - val_mae: 43.6287\n",
      "Epoch 256/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 495.9054 - mae: 14.2572 - val_loss: 6427.0059 - val_mae: 49.1358\n",
      "Epoch 257/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 556.6755 - mae: 14.8500 - val_loss: 6024.0400 - val_mae: 46.3255\n",
      "Epoch 258/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 553.2983 - mae: 15.0140 - val_loss: 5949.4443 - val_mae: 45.8609\n",
      "Epoch 259/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 496.7625 - mae: 14.5704 - val_loss: 5957.6987 - val_mae: 46.2375\n",
      "Epoch 260/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 568.1684 - mae: 15.3437 - val_loss: 5774.0962 - val_mae: 46.2215\n",
      "Epoch 261/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 751.5801 - mae: 17.8317 - val_loss: 5446.4980 - val_mae: 43.7875\n",
      "Epoch 262/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 548.7681 - mae: 14.8221 - val_loss: 5934.1313 - val_mae: 47.2727\n",
      "Epoch 263/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 537.7078 - mae: 14.6082 - val_loss: 6113.7642 - val_mae: 46.7387\n",
      "Epoch 264/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 611.7830 - mae: 15.8325 - val_loss: 6281.4595 - val_mae: 46.9587\n",
      "Epoch 265/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 624.8117 - mae: 16.2467 - val_loss: 5974.5186 - val_mae: 45.9196\n",
      "Epoch 266/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 618.9200 - mae: 16.2047 - val_loss: 5544.9717 - val_mae: 44.7196\n",
      "Epoch 267/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 558.6277 - mae: 15.1542 - val_loss: 5959.5508 - val_mae: 46.5456\n",
      "Epoch 268/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 632.4892 - mae: 16.1463 - val_loss: 5770.0327 - val_mae: 48.0147\n",
      "Epoch 269/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 526.8535 - mae: 14.6160 - val_loss: 5757.3164 - val_mae: 45.3416\n",
      "Epoch 270/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 675.9515 - mae: 16.7222 - val_loss: 5337.3433 - val_mae: 44.4266\n",
      "Epoch 271/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 561.6207 - mae: 15.3577 - val_loss: 5685.6499 - val_mae: 46.0204\n",
      "Epoch 272/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 665.7419 - mae: 16.8217 - val_loss: 6085.3169 - val_mae: 47.6470\n",
      "Epoch 273/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 500.2555 - mae: 14.1294 - val_loss: 6226.5718 - val_mae: 47.4353\n",
      "Epoch 274/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 569.9697 - mae: 15.3179 - val_loss: 6278.9971 - val_mae: 47.6409\n",
      "Epoch 275/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 525.8008 - mae: 14.7507 - val_loss: 5744.5068 - val_mae: 46.2261\n",
      "Epoch 276/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 577.1373 - mae: 15.4447 - val_loss: 5986.2500 - val_mae: 46.9908\n",
      "Epoch 277/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 467.7962 - mae: 13.7491 - val_loss: 6041.0566 - val_mae: 46.6307\n",
      "Epoch 278/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 508.2045 - mae: 14.4707 - val_loss: 6094.9912 - val_mae: 46.7195\n",
      "Epoch 279/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 478.1490 - mae: 14.1027 - val_loss: 5980.4663 - val_mae: 46.1152\n",
      "Epoch 280/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 493.4364 - mae: 14.3174 - val_loss: 6050.2256 - val_mae: 47.1115\n",
      "Epoch 281/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 517.2455 - mae: 14.6623 - val_loss: 5903.4277 - val_mae: 47.4895\n",
      "Epoch 282/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 587.1473 - mae: 15.5575 - val_loss: 6577.5400 - val_mae: 49.0144\n",
      "Epoch 283/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 640.4842 - mae: 16.4302 - val_loss: 5925.4307 - val_mae: 46.4191\n",
      "Epoch 284/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 616.6795 - mae: 16.2810 - val_loss: 6660.9414 - val_mae: 49.3637\n",
      "Epoch 285/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 748.3464 - mae: 17.6862 - val_loss: 5887.9917 - val_mae: 47.6996\n",
      "Epoch 286/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 901.0245 - mae: 19.7508 - val_loss: 5851.3809 - val_mae: 46.9800\n",
      "Epoch 287/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 846.3297 - mae: 19.1432 - val_loss: 5981.4204 - val_mae: 45.8352\n",
      "Epoch 288/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 810.7916 - mae: 18.6770 - val_loss: 5218.6602 - val_mae: 42.8930\n",
      "Epoch 289/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 662.7762 - mae: 16.3813 - val_loss: 5483.2920 - val_mae: 45.7062\n",
      "Epoch 290/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 507.6805 - mae: 14.3846 - val_loss: 5788.7363 - val_mae: 46.0839\n",
      "Epoch 291/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 477.8152 - mae: 14.0315 - val_loss: 5866.5063 - val_mae: 46.5807\n",
      "Epoch 292/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 571.1290 - mae: 15.4795 - val_loss: 5529.8052 - val_mae: 45.3082\n",
      "Epoch 293/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 506.1234 - mae: 14.4326 - val_loss: 5926.2720 - val_mae: 47.2121\n",
      "Epoch 294/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 478.7789 - mae: 14.0994 - val_loss: 5735.4619 - val_mae: 45.6209\n",
      "Epoch 295/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 410.2025 - mae: 12.8870 - val_loss: 6275.6826 - val_mae: 48.0683\n",
      "Epoch 296/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 476.8692 - mae: 14.1766 - val_loss: 5991.7217 - val_mae: 47.7513\n",
      "Epoch 297/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 656.2374 - mae: 16.4395 - val_loss: 5529.1333 - val_mae: 45.5499\n",
      "Epoch 298/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 785.4536 - mae: 18.1444 - val_loss: 5694.2324 - val_mae: 44.2568\n",
      "Epoch 299/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 755.3585 - mae: 18.3953 - val_loss: 5500.4580 - val_mae: 43.9177\n",
      "Epoch 300/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 609.4296 - mae: 15.7202 - val_loss: 6022.3550 - val_mae: 46.1101\n",
      "Epoch 301/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 487.8095 - mae: 14.2256 - val_loss: 5849.5781 - val_mae: 45.5871\n",
      "Epoch 302/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 614.0788 - mae: 16.2721 - val_loss: 6651.9814 - val_mae: 48.9468\n",
      "Epoch 303/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 740.6435 - mae: 17.8699 - val_loss: 5756.0020 - val_mae: 44.9173\n",
      "Epoch 304/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 751.1821 - mae: 17.8872 - val_loss: 6014.4595 - val_mae: 45.9876\n",
      "Epoch 305/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 636.3103 - mae: 16.4888 - val_loss: 6172.8535 - val_mae: 46.4792\n",
      "Epoch 306/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 461.7599 - mae: 13.7916 - val_loss: 5748.0342 - val_mae: 46.2200\n",
      "Epoch 307/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 771.6456 - mae: 18.4698 - val_loss: 5972.8018 - val_mae: 46.5219\n",
      "Epoch 308/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 490.7036 - mae: 14.4795 - val_loss: 6036.1479 - val_mae: 46.2499\n",
      "Epoch 309/500\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 442.1045 - mae: 13.4843 - val_loss: 5966.9644 - val_mae: 46.6962\n",
      "Epoch 310/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 436.5890 - mae: 13.2555 - val_loss: 6291.8286 - val_mae: 47.4201\n",
      "Epoch 311/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 426.0538 - mae: 13.0632 - val_loss: 5877.0498 - val_mae: 45.8703\n",
      "Epoch 312/500\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 448.0293 - mae: 13.7090 - val_loss: 6144.1074 - val_mae: 46.6516\n",
      "Epoch 313/500\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 548.1155 - mae: 14.8963 - val_loss: 5828.1582 - val_mae: 46.4628\n",
      "Epoch 314/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 418.2063 - mae: 13.0127 - val_loss: 5998.2559 - val_mae: 45.4278\n",
      "Epoch 315/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 551.5024 - mae: 15.0559 - val_loss: 5584.2295 - val_mae: 45.1129\n",
      "Epoch 316/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 517.3107 - mae: 14.8513 - val_loss: 5867.5225 - val_mae: 47.4507\n",
      "Epoch 317/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 537.5551 - mae: 15.1501 - val_loss: 6147.4438 - val_mae: 46.6041\n",
      "Epoch 318/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 528.1038 - mae: 15.1493 - val_loss: 6640.4512 - val_mae: 48.5895\n",
      "Epoch 319/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 512.4673 - mae: 14.7889 - val_loss: 5760.3096 - val_mae: 45.2273\n",
      "Epoch 320/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 438.5504 - mae: 13.5383 - val_loss: 6646.2871 - val_mae: 48.4122\n",
      "Epoch 321/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 447.2224 - mae: 13.4271 - val_loss: 6326.4336 - val_mae: 48.4805\n",
      "Epoch 322/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 420.3279 - mae: 13.2163 - val_loss: 6275.5562 - val_mae: 46.8833\n",
      "Epoch 323/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 433.0122 - mae: 13.3587 - val_loss: 5881.7559 - val_mae: 46.4722\n",
      "Epoch 324/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 565.3592 - mae: 15.5271 - val_loss: 5275.2993 - val_mae: 44.6659\n",
      "Epoch 325/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 606.3008 - mae: 15.9371 - val_loss: 5928.0874 - val_mae: 46.0790\n",
      "Epoch 326/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 497.3739 - mae: 14.6105 - val_loss: 6390.7559 - val_mae: 47.5747\n",
      "Epoch 327/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 445.6376 - mae: 13.5014 - val_loss: 5816.3779 - val_mae: 46.6463\n",
      "Epoch 328/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 401.8822 - mae: 12.8827 - val_loss: 5975.8701 - val_mae: 47.3044\n",
      "Epoch 329/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 369.3102 - mae: 12.2314 - val_loss: 5690.3701 - val_mae: 46.2195\n",
      "Epoch 330/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 403.5121 - mae: 12.8637 - val_loss: 6125.7373 - val_mae: 47.2348\n",
      "Epoch 331/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 461.4131 - mae: 13.8584 - val_loss: 6144.6182 - val_mae: 47.9504\n",
      "Epoch 332/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 448.0982 - mae: 13.7648 - val_loss: 5952.5024 - val_mae: 46.4318\n",
      "Epoch 333/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 477.1179 - mae: 13.9777 - val_loss: 6079.5220 - val_mae: 46.9481\n",
      "Epoch 334/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 512.2612 - mae: 14.6047 - val_loss: 6116.2090 - val_mae: 46.1909\n",
      "Epoch 335/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 399.2141 - mae: 12.8548 - val_loss: 5963.3345 - val_mae: 46.3449\n",
      "Epoch 336/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 487.7025 - mae: 14.1385 - val_loss: 6320.0239 - val_mae: 46.9056\n",
      "Epoch 337/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 426.7996 - mae: 12.9231 - val_loss: 6079.2617 - val_mae: 47.1494\n",
      "Epoch 338/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 425.3932 - mae: 13.3916 - val_loss: 5685.2568 - val_mae: 45.9135\n",
      "Epoch 339/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 548.0799 - mae: 15.6997 - val_loss: 5733.2246 - val_mae: 45.7876\n",
      "Epoch 340/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 608.5793 - mae: 16.3578 - val_loss: 5931.9785 - val_mae: 45.6430\n",
      "Epoch 341/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 425.0297 - mae: 13.2975 - val_loss: 6154.5840 - val_mae: 47.2196\n",
      "Epoch 342/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 342.2969 - mae: 11.9503 - val_loss: 6280.2617 - val_mae: 47.7638\n",
      "Epoch 343/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 368.8446 - mae: 12.3096 - val_loss: 5791.9180 - val_mae: 45.4426\n",
      "Epoch 344/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 450.4202 - mae: 13.8684 - val_loss: 5793.8550 - val_mae: 46.1950\n",
      "Epoch 345/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 390.0604 - mae: 12.5779 - val_loss: 5710.2280 - val_mae: 45.7934\n",
      "Epoch 346/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 426.4233 - mae: 13.4161 - val_loss: 5669.9033 - val_mae: 44.8006\n",
      "Epoch 347/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 388.4391 - mae: 12.8881 - val_loss: 6008.2930 - val_mae: 48.5915\n",
      "Epoch 348/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 460.5898 - mae: 13.9863 - val_loss: 6034.5454 - val_mae: 46.0711\n",
      "Epoch 349/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 510.1367 - mae: 14.5134 - val_loss: 6661.0205 - val_mae: 48.1066\n",
      "Epoch 350/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 474.9562 - mae: 13.8991 - val_loss: 6287.6030 - val_mae: 47.5904\n",
      "Epoch 351/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 430.3820 - mae: 13.5259 - val_loss: 6114.7090 - val_mae: 46.7931\n",
      "Epoch 352/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 431.1968 - mae: 13.4361 - val_loss: 6571.3130 - val_mae: 48.7109\n",
      "Epoch 353/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 338.2898 - mae: 11.7934 - val_loss: 5921.3267 - val_mae: 46.2838\n",
      "Epoch 354/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 400.6945 - mae: 12.9925 - val_loss: 6093.7964 - val_mae: 45.9491\n",
      "Epoch 355/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 416.3920 - mae: 13.3435 - val_loss: 5942.0898 - val_mae: 45.4978\n",
      "Epoch 356/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 358.4322 - mae: 12.0427 - val_loss: 5781.4902 - val_mae: 46.6563\n",
      "Epoch 357/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 392.2496 - mae: 12.5972 - val_loss: 6156.3486 - val_mae: 47.2913\n",
      "Epoch 358/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 399.5901 - mae: 12.9792 - val_loss: 6153.3770 - val_mae: 46.3326\n",
      "Epoch 359/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 538.2174 - mae: 15.2730 - val_loss: 6179.1538 - val_mae: 46.6915\n",
      "Epoch 360/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 555.9568 - mae: 15.4412 - val_loss: 6892.6079 - val_mae: 50.1156\n",
      "Epoch 361/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 557.4630 - mae: 15.4605 - val_loss: 6281.0811 - val_mae: 47.1615\n",
      "Epoch 362/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 359.9441 - mae: 12.1867 - val_loss: 6321.1733 - val_mae: 47.6356\n",
      "Epoch 363/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 341.6401 - mae: 11.9599 - val_loss: 6412.7573 - val_mae: 48.1490\n",
      "Epoch 364/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 451.3549 - mae: 13.7120 - val_loss: 6353.0669 - val_mae: 48.2173\n",
      "Epoch 365/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 395.9612 - mae: 12.6691 - val_loss: 6089.2739 - val_mae: 46.8603\n",
      "Epoch 366/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 554.8318 - mae: 15.6615 - val_loss: 5890.3931 - val_mae: 46.4780\n",
      "Epoch 367/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 480.7393 - mae: 14.0596 - val_loss: 6116.1143 - val_mae: 46.8501\n",
      "Epoch 368/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 533.7075 - mae: 15.1820 - val_loss: 6336.3765 - val_mae: 47.3127\n",
      "Epoch 369/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 544.4844 - mae: 15.1586 - val_loss: 5967.0781 - val_mae: 47.0278\n",
      "Epoch 370/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 405.5190 - mae: 13.0457 - val_loss: 6294.7104 - val_mae: 47.6553\n",
      "Epoch 371/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 415.6134 - mae: 13.5446 - val_loss: 6546.8105 - val_mae: 48.4015\n",
      "Epoch 372/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 408.3935 - mae: 13.0599 - val_loss: 6299.1743 - val_mae: 47.2624\n",
      "Epoch 373/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 359.4121 - mae: 12.1894 - val_loss: 6320.9175 - val_mae: 48.6615\n",
      "Epoch 374/500\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 460.6102 - mae: 13.8558 - val_loss: 5948.0610 - val_mae: 46.0460\n",
      "Epoch 375/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 357.3130 - mae: 12.1716 - val_loss: 6226.3223 - val_mae: 47.4333\n",
      "Epoch 376/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 410.7962 - mae: 13.1500 - val_loss: 6054.1211 - val_mae: 47.3536\n",
      "Epoch 377/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 365.0936 - mae: 12.3129 - val_loss: 6114.6211 - val_mae: 46.6417\n",
      "Epoch 378/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 413.4260 - mae: 13.2522 - val_loss: 6626.2090 - val_mae: 48.5059\n",
      "Epoch 379/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 365.2085 - mae: 12.3906 - val_loss: 6398.7231 - val_mae: 48.3645\n",
      "Epoch 380/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 422.4338 - mae: 13.3279 - val_loss: 5996.8467 - val_mae: 46.4607\n",
      "Epoch 381/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 361.7225 - mae: 12.3678 - val_loss: 6151.4458 - val_mae: 47.7186\n",
      "Epoch 382/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 350.8580 - mae: 12.1647 - val_loss: 6205.4751 - val_mae: 47.1082\n",
      "Epoch 383/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 420.1328 - mae: 13.3739 - val_loss: 6018.6631 - val_mae: 47.4770\n",
      "Epoch 384/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 413.9743 - mae: 13.1404 - val_loss: 6173.0674 - val_mae: 47.0547\n",
      "Epoch 385/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 377.9738 - mae: 12.6328 - val_loss: 5819.1807 - val_mae: 46.6478\n",
      "Epoch 386/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 370.0814 - mae: 12.6958 - val_loss: 6412.2026 - val_mae: 48.3207\n",
      "Epoch 387/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 503.2075 - mae: 14.2629 - val_loss: 6326.3433 - val_mae: 47.2363\n",
      "Epoch 388/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 430.4859 - mae: 13.4710 - val_loss: 6023.0698 - val_mae: 47.4925\n",
      "Epoch 389/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 420.5210 - mae: 13.1198 - val_loss: 6235.8618 - val_mae: 47.5409\n",
      "Epoch 390/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 417.2390 - mae: 13.1295 - val_loss: 5911.5806 - val_mae: 46.5204\n",
      "Epoch 391/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 494.2549 - mae: 14.4044 - val_loss: 5747.9263 - val_mae: 45.6407\n",
      "Epoch 392/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 452.9509 - mae: 14.2283 - val_loss: 6004.9961 - val_mae: 47.8865\n",
      "Epoch 393/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 385.5999 - mae: 12.8045 - val_loss: 6252.7896 - val_mae: 47.6279\n",
      "Epoch 394/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 713.6938 - mae: 17.3157 - val_loss: 5841.1523 - val_mae: 46.7158\n",
      "Epoch 395/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 653.6642 - mae: 16.8747 - val_loss: 5789.9731 - val_mae: 46.1659\n",
      "Epoch 396/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 375.4442 - mae: 12.4785 - val_loss: 6331.1611 - val_mae: 47.8139\n",
      "Epoch 397/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 359.4981 - mae: 12.2949 - val_loss: 6110.3076 - val_mae: 46.3174\n",
      "Epoch 398/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 326.4781 - mae: 11.4656 - val_loss: 5933.2817 - val_mae: 46.6324\n",
      "Epoch 399/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 443.3975 - mae: 14.1680 - val_loss: 6267.0757 - val_mae: 46.8088\n",
      "Epoch 400/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 321.8615 - mae: 11.6468 - val_loss: 6366.2217 - val_mae: 47.6224\n",
      "Epoch 401/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 310.8997 - mae: 11.2840 - val_loss: 5861.4487 - val_mae: 46.8974\n",
      "Epoch 402/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 320.4034 - mae: 11.5242 - val_loss: 6045.5801 - val_mae: 47.2257\n",
      "Epoch 403/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 318.0562 - mae: 11.6897 - val_loss: 6432.0708 - val_mae: 48.2482\n",
      "Epoch 404/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 341.4392 - mae: 11.9337 - val_loss: 6158.6465 - val_mae: 47.2738\n",
      "Epoch 405/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 341.0115 - mae: 12.1861 - val_loss: 6011.1157 - val_mae: 46.4513\n",
      "Epoch 406/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 325.6366 - mae: 11.6454 - val_loss: 6407.2163 - val_mae: 48.0482\n",
      "Epoch 407/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 425.8296 - mae: 13.3683 - val_loss: 6111.4912 - val_mae: 46.6962\n",
      "Epoch 408/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 338.3406 - mae: 12.0045 - val_loss: 6255.5952 - val_mae: 47.7901\n",
      "Epoch 409/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 464.8141 - mae: 14.2048 - val_loss: 6714.9595 - val_mae: 48.0122\n",
      "Epoch 410/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 521.2082 - mae: 15.2691 - val_loss: 5968.5361 - val_mae: 47.5359\n",
      "Epoch 411/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 466.3192 - mae: 14.0507 - val_loss: 6154.9033 - val_mae: 47.8015\n",
      "Epoch 412/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 556.2414 - mae: 15.8082 - val_loss: 5942.5830 - val_mae: 46.0601\n",
      "Epoch 413/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 380.0447 - mae: 12.7574 - val_loss: 6360.1660 - val_mae: 48.3875\n",
      "Epoch 414/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 470.3073 - mae: 14.1795 - val_loss: 6807.3193 - val_mae: 49.4936\n",
      "Epoch 415/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 398.0152 - mae: 13.1964 - val_loss: 6154.8306 - val_mae: 47.3263\n",
      "Epoch 416/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 358.0212 - mae: 12.2306 - val_loss: 6172.2476 - val_mae: 46.8321\n",
      "Epoch 417/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 353.5833 - mae: 12.1159 - val_loss: 6118.8149 - val_mae: 48.2376\n",
      "Epoch 418/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 349.2702 - mae: 12.2339 - val_loss: 6315.7012 - val_mae: 48.6877\n",
      "Epoch 419/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 337.8987 - mae: 11.7205 - val_loss: 6235.7676 - val_mae: 47.4657\n",
      "Epoch 420/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 377.7619 - mae: 12.8226 - val_loss: 6346.5913 - val_mae: 47.8105\n",
      "Epoch 421/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 308.2984 - mae: 11.2513 - val_loss: 6101.9858 - val_mae: 47.5085\n",
      "Epoch 422/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 287.4550 - mae: 10.9989 - val_loss: 6514.4214 - val_mae: 48.9362\n",
      "Epoch 423/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 313.1253 - mae: 11.5582 - val_loss: 6123.6099 - val_mae: 46.6768\n",
      "Epoch 424/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 308.6483 - mae: 11.3148 - val_loss: 6382.4126 - val_mae: 47.7231\n",
      "Epoch 425/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 358.4955 - mae: 12.1351 - val_loss: 6162.3320 - val_mae: 47.7228\n",
      "Epoch 426/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 270.5538 - mae: 10.7147 - val_loss: 6181.1860 - val_mae: 47.9340\n",
      "Epoch 427/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 306.6237 - mae: 11.2159 - val_loss: 6102.1592 - val_mae: 47.3018\n",
      "Epoch 428/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 264.2147 - mae: 10.6791 - val_loss: 6128.3354 - val_mae: 47.8702\n",
      "Epoch 429/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 464.0959 - mae: 14.1874 - val_loss: 6257.8569 - val_mae: 47.7285\n",
      "Epoch 430/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 465.6104 - mae: 13.9247 - val_loss: 5931.0674 - val_mae: 45.4598\n",
      "Epoch 431/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 480.9169 - mae: 14.5846 - val_loss: 5840.9512 - val_mae: 48.8442\n",
      "Epoch 432/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 471.6431 - mae: 14.5134 - val_loss: 6000.4043 - val_mae: 46.3623\n",
      "Epoch 433/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 454.9132 - mae: 13.7951 - val_loss: 6419.7637 - val_mae: 48.6594\n",
      "Epoch 434/500\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 347.8223 - mae: 12.3755 - val_loss: 6354.0225 - val_mae: 48.6279\n",
      "Epoch 435/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 339.3241 - mae: 12.0979 - val_loss: 6433.0127 - val_mae: 49.5204\n",
      "Epoch 436/500\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 377.2978 - mae: 12.7632 - val_loss: 6242.8794 - val_mae: 47.5621\n",
      "Epoch 437/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 409.8096 - mae: 13.0777 - val_loss: 6234.1187 - val_mae: 48.2228\n",
      "Epoch 438/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 436.1042 - mae: 13.4001 - val_loss: 6684.3252 - val_mae: 49.2290\n",
      "Epoch 439/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 434.5653 - mae: 13.8448 - val_loss: 6136.7090 - val_mae: 47.2648\n",
      "Epoch 440/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 347.1117 - mae: 12.0179 - val_loss: 6267.9829 - val_mae: 48.3372\n",
      "Epoch 441/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 360.3356 - mae: 12.4974 - val_loss: 6143.1699 - val_mae: 48.0531\n",
      "Epoch 442/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 292.0947 - mae: 11.1272 - val_loss: 6113.3350 - val_mae: 47.6160\n",
      "Epoch 443/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 253.7208 - mae: 10.3001 - val_loss: 6395.4263 - val_mae: 48.7182\n",
      "Epoch 444/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 316.4156 - mae: 11.9386 - val_loss: 6050.4058 - val_mae: 47.3752\n",
      "Epoch 445/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 336.8623 - mae: 12.1076 - val_loss: 6254.2925 - val_mae: 48.7929\n",
      "Epoch 446/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 235.7438 - mae: 10.0299 - val_loss: 6469.2129 - val_mae: 48.7928\n",
      "Epoch 447/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 243.3714 - mae: 10.2008 - val_loss: 6640.4482 - val_mae: 49.1069\n",
      "Epoch 448/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 297.7895 - mae: 11.4880 - val_loss: 6112.6133 - val_mae: 47.3352\n",
      "Epoch 449/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 276.0816 - mae: 10.7617 - val_loss: 6098.8887 - val_mae: 47.8377\n",
      "Epoch 450/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 342.1929 - mae: 12.1065 - val_loss: 6344.1470 - val_mae: 48.1810\n",
      "Epoch 451/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 287.2023 - mae: 11.0163 - val_loss: 6311.9419 - val_mae: 48.3577\n",
      "Epoch 452/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 277.1340 - mae: 10.9738 - val_loss: 6463.8818 - val_mae: 48.6180\n",
      "Epoch 453/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 334.1987 - mae: 11.8114 - val_loss: 6493.6152 - val_mae: 48.2119\n",
      "Epoch 454/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 429.5829 - mae: 13.5235 - val_loss: 6640.0830 - val_mae: 49.7361\n",
      "Epoch 455/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 786.2605 - mae: 17.9601 - val_loss: 5435.9517 - val_mae: 44.4321\n",
      "Epoch 456/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 673.7374 - mae: 16.7038 - val_loss: 5988.2856 - val_mae: 45.9265\n",
      "Epoch 457/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 466.5547 - mae: 14.0121 - val_loss: 5978.1670 - val_mae: 47.1224\n",
      "Epoch 458/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 353.2368 - mae: 12.2861 - val_loss: 5971.9888 - val_mae: 47.6665\n",
      "Epoch 459/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 321.1841 - mae: 11.9753 - val_loss: 7049.0200 - val_mae: 50.9106\n",
      "Epoch 460/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 365.7227 - mae: 12.6981 - val_loss: 6346.5542 - val_mae: 48.6127\n",
      "Epoch 461/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 491.3268 - mae: 14.7531 - val_loss: 6282.4751 - val_mae: 46.6493\n",
      "Epoch 462/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 490.4595 - mae: 14.4796 - val_loss: 7714.2212 - val_mae: 53.4224\n",
      "Epoch 463/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 625.9436 - mae: 16.7156 - val_loss: 5902.3677 - val_mae: 45.5946\n",
      "Epoch 464/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 379.9862 - mae: 12.9159 - val_loss: 6006.4067 - val_mae: 47.0638\n",
      "Epoch 465/500\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 259.7053 - mae: 10.5266 - val_loss: 6161.1621 - val_mae: 48.5127\n",
      "Epoch 466/500\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 303.8869 - mae: 11.4321 - val_loss: 6184.8301 - val_mae: 47.7529\n",
      "Epoch 467/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 250.4461 - mae: 10.0896 - val_loss: 6328.0664 - val_mae: 48.6123\n",
      "Epoch 468/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 268.2318 - mae: 10.6186 - val_loss: 6196.5532 - val_mae: 48.5574\n",
      "Epoch 469/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 323.1145 - mae: 12.1594 - val_loss: 6310.8975 - val_mae: 47.8128\n",
      "Epoch 470/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 289.5579 - mae: 10.8558 - val_loss: 6391.7251 - val_mae: 48.4712\n",
      "Epoch 471/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 257.8082 - mae: 10.4064 - val_loss: 6465.2192 - val_mae: 48.6120\n",
      "Epoch 472/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 283.2089 - mae: 11.1857 - val_loss: 6183.1387 - val_mae: 48.8467\n",
      "Epoch 473/500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 330.7214 - mae: 11.8553 - val_loss: 5939.0645 - val_mae: 46.9844\n",
      "Epoch 474/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 353.8075 - mae: 12.4246 - val_loss: 6345.2026 - val_mae: 48.7335\n",
      "Epoch 475/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 273.0113 - mae: 10.9917 - val_loss: 6407.3369 - val_mae: 48.7819\n",
      "Epoch 476/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 348.1223 - mae: 12.0509 - val_loss: 6378.2480 - val_mae: 49.1490\n",
      "Epoch 477/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 271.7010 - mae: 10.7410 - val_loss: 6160.9629 - val_mae: 48.3756\n",
      "Epoch 478/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 423.3575 - mae: 13.5826 - val_loss: 5842.3813 - val_mae: 45.3176\n",
      "Epoch 479/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 373.9922 - mae: 12.9405 - val_loss: 6206.2827 - val_mae: 47.5317\n",
      "Epoch 480/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 332.4076 - mae: 12.1128 - val_loss: 6379.4707 - val_mae: 48.4355\n",
      "Epoch 481/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 287.0489 - mae: 10.8870 - val_loss: 6372.5127 - val_mae: 49.0759\n",
      "Epoch 482/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 349.2721 - mae: 12.6072 - val_loss: 6220.8013 - val_mae: 49.4877\n",
      "Epoch 483/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 313.6075 - mae: 11.4587 - val_loss: 5939.1235 - val_mae: 47.1330\n",
      "Epoch 484/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 306.5766 - mae: 11.6488 - val_loss: 6100.6479 - val_mae: 49.2673\n",
      "Epoch 485/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 460.7387 - mae: 14.3800 - val_loss: 6226.8101 - val_mae: 47.7115\n",
      "Epoch 486/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 434.3654 - mae: 13.6832 - val_loss: 6390.8301 - val_mae: 48.4188\n",
      "Epoch 487/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 377.1698 - mae: 12.8345 - val_loss: 6142.6514 - val_mae: 48.0776\n",
      "Epoch 488/500\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 320.0452 - mae: 11.7434 - val_loss: 6047.2974 - val_mae: 47.4789\n",
      "Epoch 489/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 331.3188 - mae: 12.1753 - val_loss: 5880.9800 - val_mae: 46.3004\n",
      "Epoch 490/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 363.3084 - mae: 12.7470 - val_loss: 6211.1470 - val_mae: 48.2621\n",
      "Epoch 491/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 315.6178 - mae: 11.8109 - val_loss: 5875.1582 - val_mae: 47.0133\n",
      "Epoch 492/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 373.7875 - mae: 12.4785 - val_loss: 6074.4146 - val_mae: 47.1977\n",
      "Epoch 493/500\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 565.7876 - mae: 15.5978 - val_loss: 5701.0596 - val_mae: 45.2979\n",
      "Epoch 494/500\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 345.0502 - mae: 12.1814 - val_loss: 6324.9688 - val_mae: 47.9055\n",
      "Epoch 495/500\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 223.5481 - mae: 9.7774 - val_loss: 6392.6270 - val_mae: 48.8302\n",
      "Epoch 496/500\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 303.9480 - mae: 11.4117 - val_loss: 6790.0762 - val_mae: 49.6638\n",
      "Epoch 497/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 250.1437 - mae: 10.6897 - val_loss: 6155.2373 - val_mae: 48.6678\n",
      "Epoch 498/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 208.4311 - mae: 9.4877 - val_loss: 6363.7417 - val_mae: 48.9818\n",
      "Epoch 499/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 228.0456 - mae: 10.1116 - val_loss: 6270.8823 - val_mae: 49.1056\n",
      "Epoch 500/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 208.9876 - mae: 9.5533 - val_loss: 6406.1152 - val_mae: 48.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7e9205757c10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train[:400], labels[:400], epochs=500, batch_size=8, validation_data=(X_train[400:500], labels[400:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1711334625238,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "n15S-K-6oxNX",
    "outputId": "a03cfa85-04ee-4ef1-add8-f1236e62e458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 3575.7744 - mae: 39.3244\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(X_train[500:], labels[500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1711334625238,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "Fi7mv8Hgo2bM",
    "outputId": "ca76d979-ec17-486f-a571-2be32109dc15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3575.7744140625"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MP2-DzjOleBe"
   },
   "source": [
    "2D CNN - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bG30L_Sla-n"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32 , (3, 3), activation='relu', input_shape=(11, 11, 150)))\n",
    "model.add(layers.AveragePooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64 , (3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Reshape((1, -1)))\n",
    "model.add(layers.LSTM(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bI3R8oZinLvO"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74jYpEVfnOjJ"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train[:400], labels[:400], epochs=50, batch_size=64, validation_data=(X_train[400:], labels[400:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1707195076089,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "tuHlonGrnTBV",
    "outputId": "b0581b20-4545-44e7-dd7f-0aac18a1cabb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 4183.2939 - mae: 37.6149\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(X_train[400:], labels[400:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707195077493,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "QWg4VFrhnfoi",
    "outputId": "f3922e4a-6c86-42c4-b77d-9a2dd276033d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4183.2939453125"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wA8DIdP5yj8H"
   },
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "error",
     "timestamp": 1711723946935,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "4Ql0BFDQsQTA",
    "outputId": "84dff91f-1a2c-4839-c160-e2b0281cc436"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit scaler to data and transform it\n",
    "X_train1 = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fa-T0OuTzffn"
   },
   "outputs": [],
   "source": [
    "X_train3d = np.reshape(X_train, (600, 11, 11, 150, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1711334060776,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "myyEfMxtz0Cj",
    "outputId": "d284a558-c579-4b46-9048-3d204a31295c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 11, 11, 150, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1882,
     "status": "ok",
     "timestamp": 1711334210162,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "FZVCJKXBylIj",
    "outputId": "bd30d0a5-8251-44c1-da7b-005ac999c5aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_4 (Conv3D)           (None, 11, 11, 149, 32)   96        \n",
      "                                                                 \n",
      " average_pooling3d_4 (Avera  (None, 11, 11, 149, 32)   0         \n",
      " gePooling3D)                                                    \n",
      "                                                                 \n",
      " conv3d_5 (Conv3D)           (None, 11, 11, 148, 64)   4160      \n",
      "                                                                 \n",
      " average_pooling3d_5 (Avera  (None, 11, 11, 148, 64)   0         \n",
      " gePooling3D)                                                    \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1146112)           0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                73351232  \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73355748 (279.83 MB)\n",
      "Trainable params: 73355748 (279.83 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv3D(32, (1, 1, 2), activation='relu', input_shape=(11, 11, 150, 1)))\n",
    "model.add(layers.AveragePooling3D((1, 1, 1)))\n",
    "\n",
    "model.add(layers.Conv3D(64, (1, 1, 2), activation='relu'))\n",
    "model.add(layers.AveragePooling3D((1, 1, 1)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QY267xY60BNA"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 179575,
     "status": "error",
     "timestamp": 1711334392596,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "tc_sl4Ey0Erq",
    "outputId": "f4fa821c-6b26-4179-aafb-aa23306495f4"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train3d[:400], labels[:400], epochs=100, batch_size=8, validation_data=(X_train3d[400:500], labels[400:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kr0Npyp00fPl"
   },
   "outputs": [],
   "source": [
    "test_loss, test_mae = model.evaluate(X_train3d[500:600], labels[500:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707301256938,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "WBGDqi7W0qBo",
    "outputId": "6200213f-f649-46e3-b52d-ae966286a10c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.34287999935004"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 997
    },
    "executionInfo": {
     "elapsed": 15784,
     "status": "error",
     "timestamp": 1707472479828,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "CDA0a-mSHu6G",
    "outputId": "a1a067a7-37af-4025-82a9-54387bc0fd5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 11, 11, 150, 2)\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_26 (InputLayer)       [(None, 11, 11, 150, 1)]     0         []                            \n",
      "                                                                                                  \n",
      " input_25 (InputLayer)       [(None, 11, 11, 150, 1)]     0         []                            \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenat  (None, 11, 11, 150, 2)       0         ['input_26[0][0]',            \n",
      " e)                                                                  'input_25[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)           (None, 11, 11, 101, 32)      3232      ['concatenate_16[0][0]']      \n",
      "                                                                                                  \n",
      " average_pooling3d_4 (Avera  (None, 11, 11, 101, 32)      0         ['conv3d_5[0][0]']            \n",
      " gePooling3D)                                                                                     \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)           (None, 11, 11, 52, 64)       102464    ['average_pooling3d_4[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling3d_5 (Avera  (None, 11, 11, 52, 64)       0         ['conv3d_6[0][0]']            \n",
      " gePooling3D)                                                                                     \n",
      "                                                                                                  \n",
      " flatten_14 (Flatten)        (None, 402688)               0         ['average_pooling3d_5[0][0]'] \n",
      "                                                                                                  \n",
      " dense_27 (Dense)            (None, 64)                   2577209   ['flatten_14[0][0]']          \n",
      "                                                          6                                       \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 4)                    260       ['dense_27[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25878052 (98.72 MB)\n",
      "Trainable params: 25878052 (98.72 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      " 2/13 [===>..........................] - ETA: 1:04 - loss: 624182912.0000 - mae: 15200.5254"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-761bb560c76f>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m history = model.fit([X_train1[:400], M_train1[:400]], labels[:400], epochs=100, \n\u001b[0m\u001b[1;32m     32\u001b[0m                     validation_data=([X_train1[400:], M_train1[400:] ], labels[400:]))\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "masked_input = layers.Input(shape=(11, 11, 150, 1))\n",
    "data_input = layers.Input(shape=(11, 11, 150, 1))\n",
    "\n",
    "# Concatenate the input tensors along the channel dimension\n",
    "combined_input = layers.Concatenate()([data_input, masked_input])\n",
    "print(combined_input.shape)\n",
    "\n",
    "# Define the model architecture\n",
    "conv1 = layers.Conv3D(32, (1, 1, 50), activation='relu')(combined_input)\n",
    "pool1 = layers.AveragePooling3D((1, 1, 1))(conv1)\n",
    "conv2 = layers.Conv3D(64, (1, 1, 50), activation='relu')(pool1)\n",
    "pool2 = layers.AveragePooling3D((1, 1, 1))(conv2)\n",
    "flatten = layers.Flatten()(pool2)\n",
    "dense1 = layers.Dense(64, activation='relu')(flatten)\n",
    "output = layers.Dense(4, activation='linear')(dense1)\n",
    "\n",
    "# Combine input and output layers to create the model\n",
    "model = models.Model(inputs=[masked_input, data_input], outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',  # Use appropriate loss function based on your task\n",
    "              metrics=['mae'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([X_train1[:400], M_train1[:400]], labels[:400], epochs=100,\n",
    "                    validation_data=([X_train1[400:], M_train1[400:] ], labels[400:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OeQzEAuZNZzp"
   },
   "outputs": [],
   "source": [
    "X_train1 = np.reshape(X_train, (500, 11, 11, 150, 1))\n",
    "M_train1 = np.reshape(M_train, (500, 11, 11, 150, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25B4-JIgmgi8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE_PX = 11\n",
    "SLICE_COUNT = 150\n",
    "\n",
    "n_classes = 4\n",
    "batch_size = 8\n",
    "\n",
    "# x = tf.keras.Input(shape=(IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT), dtype=tf.float32)\n",
    "# y = tf.keras.Input(shape=(n_classes,), dtype=tf.float32)\n",
    "\n",
    "keep_rate = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poj76sX8nnmi"
   },
   "outputs": [],
   "source": [
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool3d(x):\n",
    "    #                        size of window         movement of window as you slide about\n",
    "    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1706864459813,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "3_80lSjpAZZ5",
    "outputId": "f8146ac7-7530-4953-b95a-1947a2617559"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([ 0.10115086, -1.945691  ,  0.40285757,  2.0383766 ,  0.9953945 ,\n",
       "       -0.5809935 , -0.16286004,  0.40759248,  0.80625445,  0.9287159 ,\n",
       "       -0.8120495 ,  0.4027626 ,  0.8993472 ,  0.35830373, -0.5414212 ,\n",
       "       -0.32793972,  0.16521011,  0.9224293 ,  0.38775307,  0.15323867,\n",
       "        0.55029154, -1.7037054 , -0.3455817 ,  0.58982235, -0.9495313 ,\n",
       "       -1.9628018 ,  0.7868988 ,  0.41960946, -0.0120301 ,  0.7725604 ,\n",
       "       -0.5845273 ,  0.5482695 ,  0.29339278, -0.03294135,  1.5558783 ,\n",
       "       -0.59621173, -1.5498742 ,  1.9917103 ,  0.16328098,  0.4209951 ,\n",
       "       -0.8351074 ,  1.0565029 ,  1.2185313 ,  1.5713726 ,  1.066861  ,\n",
       "        0.6522824 ,  0.47756088,  1.8227777 , -1.1260029 , -1.4623476 ,\n",
       "        0.52278   ,  0.09903459,  0.4662738 ,  0.09560031,  1.0857383 ,\n",
       "       -1.564737  ,  1.1949328 , -1.2593824 ,  0.8328553 ,  1.3161554 ,\n",
       "       -0.00966072,  1.0146114 ,  0.42456573,  0.2063071 ], dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal([64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDHTXKtvn9WP"
   },
   "outputs": [],
   "source": [
    "def convolutional_neural_network(x):\n",
    "    #                # 5 x 5 x 5 patches, 1 channel, 32 features to compute.\n",
    "    weights = {'W_conv1':tf.Variable(tf.random.normal([3,3,3,1,32])),\n",
    "               #       5 x 5 x 5 patches, 32 channels, 64 features to compute.\n",
    "               'W_conv2':tf.Variable(tf.random.normal([3,3,3,32,64])),\n",
    "               #                                  64 features\n",
    "               'W_fc':tf.Variable(tf.random.normal([21888,1024])),\n",
    "               'out':tf.Variable(tf.random.normal([1024, n_classes]))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random.normal([32])),\n",
    "               'b_conv2':tf.Variable(tf.random.normal([64])),\n",
    "               'b_fc':tf.Variable(tf.random.normal([1024])),\n",
    "               'out':tf.Variable(tf.random.normal([n_classes]))}\n",
    "\n",
    "    #                            image X      image Y        image Z\n",
    "    x = tf.reshape(x, shape=[-1, IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool3d(conv1)\n",
    "\n",
    "    print(conv1.shape)\n",
    "\n",
    "\n",
    "    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool3d(conv2)\n",
    "\n",
    "    print(conv2.shape)\n",
    "\n",
    "    fc = tf.reshape(conv2,[-1, 21888])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, keep_rate)\n",
    "\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uO3zw5wIo20t"
   },
   "outputs": [],
   "source": [
    "type(labels)\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1706864459814,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "mCN4ukEhCPKZ",
    "outputId": "ff708718-861c-4390-df0a-bb940a34fabf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mpiBJZF9uq7"
   },
   "outputs": [],
   "source": [
    "X = tf.cast(X, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1706864459814,
     "user": {
      "displayName": "Priyanshu Gupta",
      "userId": "04165208456498233301"
     },
     "user_tz": -330
    },
    "id": "wMzcIFyH-5iy",
    "outputId": "a65f2413-6665-4b6b-8514-42769b3e1de5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPf8lcLMQ63Q3bASp2jLJ7Z",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12e820d687254b22a3b8eabbe9e306cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b64039e080f49a3ad329d05e7914a8c",
       "IPY_MODEL_dfcae9a7d415438382a7369ce13a06ef",
       "IPY_MODEL_7c4f731ff4a2408192578eca04b8d210"
      ],
      "layout": "IPY_MODEL_b1e99f6834be4271b09d127d10162e26"
     }
    },
    "3dd0fe6a7f8e4e5c84ff0a23bd5019af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b64039e080f49a3ad329d05e7914a8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a527ca861c844e61b32982dc8438a03b",
      "placeholder": "",
      "style": "IPY_MODEL_f3d3b3fde92147b79d76bc8c357c6cd9",
      "value": "Loadingtrainingdata..:100%"
     }
    },
    "787c5f96e2c94a9eada3ad58c1416376": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c4f731ff4a2408192578eca04b8d210": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3dd0fe6a7f8e4e5c84ff0a23bd5019af",
      "placeholder": "",
      "style": "IPY_MODEL_935e7cc95acd40e991b519c9316343f2",
      "value": "1/1[00:00&lt;00:00,2.19it/s]"
     }
    },
    "935e7cc95acd40e991b519c9316343f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fc23f9f7dd84974ae9d78fcfbb3b825": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a527ca861c844e61b32982dc8438a03b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1e99f6834be4271b09d127d10162e26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfcae9a7d415438382a7369ce13a06ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_787c5f96e2c94a9eada3ad58c1416376",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9fc23f9f7dd84974ae9d78fcfbb3b825",
      "value": 1
     }
    },
    "f3d3b3fde92147b79d76bc8c357c6cd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
